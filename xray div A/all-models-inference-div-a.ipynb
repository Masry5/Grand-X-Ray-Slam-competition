{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21be370d",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-10-03T09:36:38.841688Z",
     "iopub.status.busy": "2025-10-03T09:36:38.841489Z",
     "iopub.status.idle": "2025-10-03T09:37:59.828486Z",
     "shell.execute_reply": "2025-10-03T09:37:59.827536Z"
    },
    "papermill": {
     "duration": 80.996284,
     "end_time": "2025-10-03T09:37:59.830144",
     "exception": false,
     "start_time": "2025-10-03T09:36:38.833860",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fvcore\r\n",
      "  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from fvcore) (1.26.4)\r\n",
      "Collecting yacs>=0.1.6 (from fvcore)\r\n",
      "  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from fvcore) (6.0.2)\r\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from fvcore) (4.67.1)\r\n",
      "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.11/dist-packages (from fvcore) (3.1.0)\r\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from fvcore) (11.2.1)\r\n",
      "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from fvcore) (0.9.0)\r\n",
      "Collecting iopath>=0.1.7 (from fvcore)\r\n",
      "  Downloading iopath-0.1.10.tar.gz (42 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from iopath>=0.1.7->fvcore) (4.14.0)\r\n",
      "Collecting portalocker (from iopath>=0.1.7->fvcore)\r\n",
      "  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->fvcore) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->fvcore) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->fvcore) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->fvcore) (2025.2.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->fvcore) (2022.2.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->fvcore) (2.4.1)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->fvcore) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->fvcore) (2022.2.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->fvcore) (1.4.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->fvcore) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->fvcore) (2024.2.0)\r\n",
      "Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\r\n",
      "Downloading portalocker-3.2.0-py3-none-any.whl (22 kB)\r\n",
      "Building wheels for collected packages: fvcore, iopath\r\n",
      "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61397 sha256=9486cd582ade6abf00e16c1488011c32dcfc6b5543a1275d15fa0db912741240\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/65/71/95/3b8fde5c65c6e4a806e0867c1651dcc71a1cb2f3430e8f355f\r\n",
      "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31527 sha256=fc845bdc5d76e9b2ca8304854407679f955b1410f2f141610f3c6dd89741136e\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/ba/5e/16/6117f8fe7e9c0c161a795e10d94645ebcf301ccbd01f66d8ec\r\n",
      "Successfully built fvcore iopath\r\n",
      "Installing collected packages: yacs, portalocker, iopath, fvcore\r\n",
      "Successfully installed fvcore-0.1.5.post20221221 iopath-0.1.10 portalocker-3.2.0 yacs-0.1.8\r\n",
      "Collecting open_clip_torch\r\n",
      "  Downloading open_clip_torch-3.2.0-py3-none-any.whl.metadata (32 kB)\r\n",
      "Requirement already satisfied: torch>=2.0 in /usr/local/lib/python3.11/dist-packages (from open_clip_torch) (2.6.0+cu124)\r\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from open_clip_torch) (0.21.0+cu124)\r\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from open_clip_torch) (2024.11.6)\r\n",
      "Collecting ftfy (from open_clip_torch)\r\n",
      "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\r\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from open_clip_torch) (4.67.1)\r\n",
      "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/dist-packages (from open_clip_torch) (0.33.1)\r\n",
      "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from open_clip_torch) (0.5.3)\r\n",
      "Collecting timm>=1.0.17 (from open_clip_torch)\r\n",
      "  Downloading timm-1.0.20-py3-none-any.whl.metadata (61 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.7/61.7 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from timm>=1.0.17->open_clip_torch) (6.0.2)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->open_clip_torch) (3.18.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->open_clip_torch) (4.14.0)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->open_clip_torch) (3.5)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->open_clip_torch) (3.1.6)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->open_clip_torch) (2025.5.1)\r\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0->open_clip_torch)\r\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0->open_clip_torch)\r\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0->open_clip_torch)\r\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0->open_clip_torch)\r\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0->open_clip_torch)\r\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0->open_clip_torch)\r\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0->open_clip_torch)\r\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0->open_clip_torch)\r\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0->open_clip_torch)\r\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->open_clip_torch) (0.6.2)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->open_clip_torch) (2.21.5)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->open_clip_torch) (12.4.127)\r\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0->open_clip_torch)\r\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->open_clip_torch) (3.2.0)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->open_clip_torch) (1.13.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0->open_clip_torch) (1.3.0)\r\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy->open_clip_torch) (0.2.13)\r\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->open_clip_torch) (25.0)\r\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->open_clip_torch) (2.32.4)\r\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->open_clip_torch) (1.1.5)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision->open_clip_torch) (1.26.4)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->open_clip_torch) (11.2.1)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0->open_clip_torch) (3.0.2)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->open_clip_torch) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->open_clip_torch) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->open_clip_torch) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->open_clip_torch) (2025.2.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->open_clip_torch) (2022.2.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->open_clip_torch) (2.4.1)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->open_clip_torch) (3.4.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->open_clip_torch) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->open_clip_torch) (2.5.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->open_clip_torch) (2025.6.15)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision->open_clip_torch) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision->open_clip_torch) (2022.2.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torchvision->open_clip_torch) (1.4.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torchvision->open_clip_torch) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torchvision->open_clip_torch) (2024.2.0)\r\n",
      "Downloading open_clip_torch-3.2.0-py3-none-any.whl (1.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading timm-1.0.20-py3-none-any.whl (2.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m90.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m70.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading ftfy-6.3.1-py3-none-any.whl (44 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ftfy, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, timm, open_clip_torch\r\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\r\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-curand-cu12\r\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\r\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\r\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\r\n",
      "  Attempting uninstall: nvidia-cufft-cu12\r\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\r\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\r\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\r\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\r\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\r\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\r\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cublas-cu12\r\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\r\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\r\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\r\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\r\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\r\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\r\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\r\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\r\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\r\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\r\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\r\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\r\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\r\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\r\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\r\n",
      "  Attempting uninstall: timm\r\n",
      "    Found existing installation: timm 1.0.15\r\n",
      "    Uninstalling timm-1.0.15:\r\n",
      "      Successfully uninstalled timm-1.0.15\r\n",
      "Successfully installed ftfy-6.3.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 open_clip_torch-3.2.0 timm-1.0.20\r\n"
     ]
    }
   ],
   "source": [
    "!pip install fvcore\n",
    "!pip install open_clip_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "190a2607",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T09:37:59.886782Z",
     "iopub.status.busy": "2025-10-03T09:37:59.886551Z",
     "iopub.status.idle": "2025-10-03T09:38:01.359073Z",
     "shell.execute_reply": "2025-10-03T09:38:01.358449Z"
    },
    "papermill": {
     "duration": 1.502052,
     "end_time": "2025-10-03T09:38:01.360718",
     "exception": false,
     "start_time": "2025-10-03T09:37:59.858666",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "test_df = pd.read_csv('/kaggle/input/grand-xray-slam-division-a/sample_submission_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62c56267",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T09:38:01.417940Z",
     "iopub.status.busy": "2025-10-03T09:38:01.417204Z",
     "iopub.status.idle": "2025-10-03T09:38:01.420968Z",
     "shell.execute_reply": "2025-10-03T09:38:01.420288Z"
    },
    "papermill": {
     "duration": 0.032974,
     "end_time": "2025-10-03T09:38:01.422165",
     "exception": false,
     "start_time": "2025-10-03T09:38:01.389191",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_images_folder='/kaggle/input/600-p-div-a-data/test1_resized'\n",
    "\n",
    "chexfound_folder_path='/kaggle/input/all-data-chexfound-recs-xray-div-a-models'\n",
    "\n",
    "evax448_folder_path_ep5='/kaggle/input/evax-recs-448-div-a'\n",
    "evax448_folder_path_ep6='/kaggle/input/evax-recs-448-div-a'\n",
    "\n",
    "evax224_folder_path='/kaggle/input/evax-div-a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5455043c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T09:38:01.477684Z",
     "iopub.status.busy": "2025-10-03T09:38:01.477482Z",
     "iopub.status.idle": "2025-10-03T09:38:01.480987Z",
     "shell.execute_reply": "2025-10-03T09:38:01.480307Z"
    },
    "papermill": {
     "duration": 0.032272,
     "end_time": "2025-10-03T09:38:01.482141",
     "exception": false,
     "start_time": "2025-10-03T09:38:01.449869",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels_cols=[\n",
    "            \"Atelectasis\",\n",
    "            \"Cardiomegaly\",\n",
    "            \"Consolidation\",\n",
    "            \"Edema\",\n",
    "            \"Enlarged Cardiomediastinum\",\n",
    "            \"Fracture\",\n",
    "            \"Lung Lesion\",\n",
    "            \"Lung Opacity\",\n",
    "            \"No Finding\",\n",
    "            \"Pleural Effusion\",\n",
    "            \"Pleural Other\",\n",
    "            \"Pneumonia\",\n",
    "            \"Pneumothorax\",\n",
    "            \"Support Devices\",\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6babbf64",
   "metadata": {
    "papermill": {
     "duration": 0.028246,
     "end_time": "2025-10-03T09:38:01.582047",
     "exception": false,
     "start_time": "2025-10-03T09:38:01.553801",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# chexfound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f13cfc9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T09:38:01.639728Z",
     "iopub.status.busy": "2025-10-03T09:38:01.639461Z",
     "iopub.status.idle": "2025-10-03T09:38:01.643223Z",
     "shell.execute_reply": "2025-10-03T09:38:01.642471Z"
    },
    "papermill": {
     "duration": 0.033695,
     "end_time": "2025-10-03T09:38:01.644422",
     "exception": false,
     "start_time": "2025-10-03T09:38:01.610727",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "repo_path = f\"{chexfound_folder_path}/CheXFound\"\n",
    "if repo_path not in sys.path:\n",
    "    sys.path.insert(0, repo_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b86291f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T09:38:01.701670Z",
     "iopub.status.busy": "2025-10-03T09:38:01.701295Z",
     "iopub.status.idle": "2025-10-03T09:38:30.652980Z",
     "shell.execute_reply": "2025-10-03T09:38:30.652321Z"
    },
    "papermill": {
     "duration": 28.98103,
     "end_time": "2025-10-03T09:38:30.654405",
     "exception": false,
     "start_time": "2025-10-03T09:38:01.673375",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/input/all-data-chexfound-recs-xray-div-a-models/CheXFound/chexfound/layers/swiglu_ffn.py:51: UserWarning: xFormers is not available (SwiGLU)\n",
      "  warnings.warn(\"xFormers is not available (SwiGLU)\")\n",
      "/kaggle/input/all-data-chexfound-recs-xray-div-a-models/CheXFound/chexfound/layers/attention.py:33: UserWarning: xFormers is not available (Attention)\n",
      "  warnings.warn(\"xFormers is not available (Attention)\")\n",
      "/kaggle/input/all-data-chexfound-recs-xray-div-a-models/CheXFound/chexfound/layers/block.py:40: UserWarning: xFormers is not available (Block)\n",
      "  warnings.warn(\"xFormers is not available (Block)\")\n",
      "2025-10-03 09:38:16.028257: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1759484296.180108      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1759484296.222526      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "#os.chdir('/kaggle/working/CheXFound')  # Change this path to the repository path\n",
    "import json\n",
    "import torch\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from chexfound.eval.setup import setup_and_build_model\n",
    "from chexfound.data.transforms import make_classification_eval_transform\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from chexfound.eval.utils import extract_hyperparameters_from_model\n",
    "from chexfound.eval.classification.utils import setup_glori\n",
    "from fvcore.common.checkpoint import Checkpointer\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import torchvision.io as io\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, KFold\n",
    "from torch.amp import autocast, GradScaler\n",
    "from torchvision.transforms import autoaugment, transforms\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "import copy\n",
    "import torch.nn.functional as F\n",
    "from torch.amp import autocast, GradScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from timm.models.eva import Eva\n",
    "from timm.layers import resample_abs_pos_embed, resample_patch_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9123df33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T09:38:30.714162Z",
     "iopub.status.busy": "2025-10-03T09:38:30.713607Z",
     "iopub.status.idle": "2025-10-03T09:38:30.717573Z",
     "shell.execute_reply": "2025-10-03T09:38:30.716919Z"
    },
    "papermill": {
     "duration": 0.033335,
     "end_time": "2025-10-03T09:38:30.719053",
     "exception": false,
     "start_time": "2025-10-03T09:38:30.685718",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6a64fcf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T09:38:30.798041Z",
     "iopub.status.busy": "2025-10-03T09:38:30.797599Z",
     "iopub.status.idle": "2025-10-03T09:38:30.803958Z",
     "shell.execute_reply": "2025-10-03T09:38:30.803225Z"
    },
    "papermill": {
     "duration": 0.045286,
     "end_time": "2025-10-03T09:38:30.805079",
     "exception": false,
     "start_time": "2025-10-03T09:38:30.759793",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_dir = f'{chexfound_folder_path}/CheXFound_Model/'  # Change to the directory storing checkpoints and configuration files\n",
    "\n",
    "config_file = base_dir + 'config.yaml'\n",
    "pretrained_weights = base_dir + 'teacher_checkpoint.pth'\n",
    "classifier_fpath = base_dir + 'glori.pth'\n",
    "classifier_json = base_dir + 'results_eval_linear.json'\n",
    "output_dir = base_dir + 'example'\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04eeb33d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T09:38:30.861034Z",
     "iopub.status.busy": "2025-10-03T09:38:30.860350Z",
     "iopub.status.idle": "2025-10-03T09:38:30.864957Z",
     "shell.execute_reply": "2025-10-03T09:38:30.864409Z"
    },
    "papermill": {
     "duration": 0.03338,
     "end_time": "2025-10-03T09:38:30.865925",
     "exception": false,
     "start_time": "2025-10-03T09:38:30.832545",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.set_defaults(\n",
    "    config_file=config_file,  # path to architecture configuration files\n",
    "    pretrained_weights=None,\n",
    "    output_dir=output_dir,\n",
    "    opts=[],\n",
    "    image_size=512,\n",
    "    patch_size=16,\n",
    "    n_register_tokens=4,\n",
    "    n_last_blocks=4,\n",
    "    return_class_token=True,\n",
    "    num_classes=40,\n",
    "    num_heads=8,\n",
    ")\n",
    "args, unknown = parser.parse_known_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7bb94fee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T09:38:30.923404Z",
     "iopub.status.busy": "2025-10-03T09:38:30.922966Z",
     "iopub.status.idle": "2025-10-03T09:38:31.078011Z",
     "shell.execute_reply": "2025-10-03T09:38:31.077133Z"
    },
    "papermill": {
     "duration": 0.18475,
     "end_time": "2025-10-03T09:38:31.079353",
     "exception": false,
     "start_time": "2025-10-03T09:38:30.894603",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!git config --global --add safe.directory /kaggle/input/all-data-chexfound-recs-xray-div-a-models/CheXFound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9996f0ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T09:38:31.135772Z",
     "iopub.status.busy": "2025-10-03T09:38:31.135548Z",
     "iopub.status.idle": "2025-10-03T09:38:37.373854Z",
     "shell.execute_reply": "2025-10-03T09:38:37.373202Z"
    },
    "papermill": {
     "duration": 6.267854,
     "end_time": "2025-10-03T09:38:37.375345",
     "exception": false,
     "start_time": "2025-10-03T09:38:31.107491",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[rank0]:[W1003 09:38:31.848066178 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I20251003 09:38:32 19 chexfound config.py:60] git:\n",
      "  sha: a4bac4956f3eeba4a8b2c15410c600536c7b0bce, status: has uncommitted changes, branch: main\n",
      "\n",
      "I20251003 09:38:32 19 chexfound config.py:61] config_file: /kaggle/input/all-data-chexfound-recs-xray-div-a-models/CheXFound_Model/config.yaml\n",
      "image_size: 512\n",
      "n_last_blocks: 4\n",
      "n_register_tokens: 4\n",
      "num_classes: 40\n",
      "num_heads: 8\n",
      "opts: ['train.output_dir=/kaggle/working']\n",
      "output_dir: /kaggle/working\n",
      "patch_size: 16\n",
      "pretrained_weights: None\n",
      "return_class_token: True\n",
      "I20251003 09:38:32 19 chexfound config.py:26] sqrt scaling learning rate; base: 0.0002, new: 2.3385358667337133e-05\n",
      "I20251003 09:38:32 19 chexfound config.py:33] MODEL:\n",
      "  WEIGHTS: ''\n",
      "compute_precision:\n",
      "  grad_scaler: true\n",
      "  teacher:\n",
      "    backbone:\n",
      "      sharding_strategy: SHARD_GRAD_OP\n",
      "      mixed_precision:\n",
      "        param_dtype: fp16\n",
      "        reduce_dtype: fp16\n",
      "        buffer_dtype: fp32\n",
      "    dino_head:\n",
      "      sharding_strategy: SHARD_GRAD_OP\n",
      "      mixed_precision:\n",
      "        param_dtype: fp16\n",
      "        reduce_dtype: fp16\n",
      "        buffer_dtype: fp32\n",
      "    ibot_head:\n",
      "      sharding_strategy: SHARD_GRAD_OP\n",
      "      mixed_precision:\n",
      "        param_dtype: fp16\n",
      "        reduce_dtype: fp16\n",
      "        buffer_dtype: fp32\n",
      "  student:\n",
      "    backbone:\n",
      "      sharding_strategy: SHARD_GRAD_OP\n",
      "      mixed_precision:\n",
      "        param_dtype: fp16\n",
      "        reduce_dtype: fp16\n",
      "        buffer_dtype: fp32\n",
      "    dino_head:\n",
      "      sharding_strategy: SHARD_GRAD_OP\n",
      "      mixed_precision:\n",
      "        param_dtype: fp16\n",
      "        reduce_dtype: fp32\n",
      "        buffer_dtype: fp32\n",
      "    ibot_head:\n",
      "      sharding_strategy: SHARD_GRAD_OP\n",
      "      mixed_precision:\n",
      "        param_dtype: fp16\n",
      "        reduce_dtype: fp32\n",
      "        buffer_dtype: fp32\n",
      "dino:\n",
      "  loss_weight: 1.0\n",
      "  head_n_prototypes: 131072\n",
      "  head_bottleneck_dim: 384\n",
      "  head_nlayers: 3\n",
      "  head_hidden_dim: 2048\n",
      "  koleo_loss_weight: 0.1\n",
      "ibot:\n",
      "  loss_weight: 3.0\n",
      "  mask_sample_probability: 0.5\n",
      "  mask_ratio_min_max:\n",
      "  - 0.1\n",
      "  - 0.5\n",
      "  separate_head: true\n",
      "  head_n_prototypes: 131072\n",
      "  head_bottleneck_dim: 256\n",
      "  head_nlayers: 3\n",
      "  head_hidden_dim: 2048\n",
      "train:\n",
      "  batch_size_per_gpu: 14\n",
      "  dataset_path: CXRDatabase:split=TRAIN:root=/fast/yangz16/outputs/dinov2_split_512:extra=/fast/yangz16/outputs/dinov2_split_512/extra\n",
      "  output_dir: /kaggle/working\n",
      "  saveckp_freq: 20\n",
      "  seed: 0\n",
      "  num_workers: 40\n",
      "  OFFICIAL_EPOCH_LENGTH: 2500\n",
      "  cache_dataset: true\n",
      "  centering: sinkhorn_knopp\n",
      "student:\n",
      "  arch: vit_large\n",
      "  patch_size: 16\n",
      "  drop_path_rate: 0.4\n",
      "  layerscale: 1.0e-05\n",
      "  drop_path_uniform: true\n",
      "  pretrained_weights: ''\n",
      "  ffn_layer: swiglufused\n",
      "  block_chunks: 0\n",
      "  qkv_bias: true\n",
      "  proj_bias: true\n",
      "  ffn_bias: true\n",
      "  num_register_tokens: 4\n",
      "  interpolate_antialias: false\n",
      "  interpolate_offset: 0.1\n",
      "teacher:\n",
      "  momentum_teacher: 0.994\n",
      "  final_momentum_teacher: 1\n",
      "  warmup_teacher_temp: 0.04\n",
      "  teacher_temp: 0.07\n",
      "  warmup_teacher_temp_epochs: 30\n",
      "optim:\n",
      "  epochs: 100\n",
      "  weight_decay: 0.04\n",
      "  weight_decay_end: 0.2\n",
      "  base_lr: 0.0002\n",
      "  lr: 2.3385358667337133e-05\n",
      "  warmup_epochs: 10\n",
      "  min_lr: 1.0e-06\n",
      "  clip_grad: 3.0\n",
      "  freeze_last_layer_epochs: 1\n",
      "  scaling_rule: sqrt_wrt_1024\n",
      "  patch_embed_lr_mult: 0.2\n",
      "  layerwise_decay: 1.0\n",
      "  adamw_beta1: 0.9\n",
      "  adamw_beta2: 0.999\n",
      "crops:\n",
      "  global_crops_scale:\n",
      "  - 0.32\n",
      "  - 1.0\n",
      "  local_crops_number: 8\n",
      "  local_crops_scale:\n",
      "  - 0.05\n",
      "  - 0.32\n",
      "  global_crops_size: 512\n",
      "  local_crops_size: 144\n",
      "evaluation:\n",
      "  eval_period_iterations: 5000\n",
      "\n",
      "I20251003 09:38:32 19 chexfound vision_transformer.py:125] using SwiGLU layer as FFN\n"
     ]
    }
   ],
   "source": [
    "args.output_dir = \"\"\n",
    "\n",
    "#os.makedirs(args.output_dir, exist_ok=True)\n",
    "base_model, autocast_dtype = setup_and_build_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0070bf94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T09:38:37.435054Z",
     "iopub.status.busy": "2025-10-03T09:38:37.434276Z",
     "iopub.status.idle": "2025-10-03T09:38:38.183148Z",
     "shell.execute_reply": "2025-10-03T09:38:38.182527Z"
    },
    "papermill": {
     "duration": 0.779803,
     "end_time": "2025-10-03T09:38:38.184426",
     "exception": false,
     "start_time": "2025-10-03T09:38:37.404623",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set up glori head\n",
    "log_json = classifier_json\n",
    "with open(log_json, 'r') as f:\n",
    "    content = f.read().split('\\n')[-3]\n",
    "    data = json.loads(content)\n",
    "best_classifier_str = data['best_classifier']['name']\n",
    "hyperparameters = extract_hyperparameters_from_model(best_classifier_str)\n",
    "learning_rate, avgpool, block = hyperparameters[\"lr\"], hyperparameters[\"avgpool\"], hyperparameters[\"blocks\"]\n",
    "\n",
    "sample_input = torch.randn(1, 3, 512, 512).cuda()\n",
    "with torch.no_grad():\n",
    "    sample_output = base_model.get_intermediate_layers(sample_input, n=args.n_last_blocks, return_class_token=True)\n",
    "\n",
    "glori, _ = setup_glori(\n",
    "    sample_output=sample_output,\n",
    "    n_last_blocks_list=block,\n",
    "    learning_rates=learning_rate,\n",
    "    avgpools=avgpool,\n",
    "    num_classes=args.num_classes,\n",
    "    multiview=False,\n",
    "    decoder_dim=768,\n",
    "    cat_cls=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "124b44d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T09:38:38.242155Z",
     "iopub.status.busy": "2025-10-03T09:38:38.241934Z",
     "iopub.status.idle": "2025-10-03T09:38:38.255013Z",
     "shell.execute_reply": "2025-10-03T09:38:38.254374Z"
    },
    "papermill": {
     "duration": 0.04273,
     "end_time": "2025-10-03T09:38:38.256030",
     "exception": false,
     "start_time": "2025-10-03T09:38:38.213300",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder found: <class 'chexfound.eval.classification.glori.TransformerDecoder'>\n",
      "Decoder.num_classes (before): 40\n",
      "Set decoder.num_classes -> 14\n",
      "Old duplicate_pooling_bias shape: (40,)\n",
      "Replaced duplicate_pooling_bias with shape: torch.Size([14])\n",
      "Replaced parameter/buffer names: []\n",
      "Moved glori to device.\n"
     ]
    }
   ],
   "source": [
    "# ---------- Fix decoder internals (resize biases / num_classes) ----------\n",
    "import torch.nn as nn\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "TARGET_CLASSES = 14\n",
    "ORIG_CLASSES = 40\n",
    "\n",
    "# get classifier same way as before\n",
    "glori_wrapped = glori\n",
    "glori_module = getattr(glori_wrapped, \"module\", glori_wrapped)\n",
    "classifier_key = next(iter(glori_module.classifiers_dict.keys()))\n",
    "classifier = glori_module.classifiers_dict[classifier_key]\n",
    "decoder = getattr(classifier, \"decoder\", None)\n",
    "if decoder is None:\n",
    "    raise RuntimeError(\"Decoder not found in classifier; cannot resize num_classes. Print classifier to inspect.\")\n",
    "\n",
    "print(\"Decoder found:\", type(decoder))\n",
    "print(\"Decoder.num_classes (before):\", getattr(decoder, \"num_classes\", None))\n",
    "\n",
    "# 1) set decoder.num_classes\n",
    "decoder.num_classes = TARGET_CLASSES\n",
    "print(\"Set decoder.num_classes ->\", decoder.num_classes)\n",
    "\n",
    "# 2) replace duplicate_pooling_bias if exists (common in this implementation)\n",
    "if hasattr(decoder, \"duplicate_pooling_bias\"):\n",
    "    old = decoder.duplicate_pooling_bias\n",
    "    print(\"Old duplicate_pooling_bias shape:\", tuple(old.shape) if isinstance(old, torch.Tensor) else type(old))\n",
    "    # create new bias param\n",
    "    new_bias = nn.Parameter(torch.zeros(TARGET_CLASSES, dtype=torch.float32, device=device))\n",
    "    # init small (optional)\n",
    "    nn.init.constant_(new_bias, 0.0)\n",
    "    # assign (if module originally on CPU, move)\n",
    "    decoder.duplicate_pooling_bias = new_bias\n",
    "    print(\"Replaced duplicate_pooling_bias with shape:\", decoder.duplicate_pooling_bias.shape)\n",
    "else:\n",
    "    print(\"No attribute duplicate_pooling_bias found on decoder — fine.\")\n",
    "\n",
    "# 3) scan decoder for any 1D parameters/buffers whose length equals ORIG_CLASSES and replace them (safe heuristic)\n",
    "replaced = []\n",
    "for name, param in list(decoder.named_parameters()):\n",
    "    if param.dim() == 1 and param.shape[0] == ORIG_CLASSES:\n",
    "        print(f\"Resizing param: {name} shape {param.shape} -> {TARGET_CLASSES}\")\n",
    "        parent = decoder\n",
    "        parts = name.split('.')\n",
    "        for p in parts[:-1]:\n",
    "            parent = getattr(parent, p)\n",
    "        attr = parts[-1]\n",
    "        new_p = nn.Parameter(torch.zeros(TARGET_CLASSES, dtype=param.dtype, device=device))\n",
    "        setattr(parent, attr, new_p)\n",
    "        replaced.append(name)\n",
    "\n",
    "# also check buffers (non-parameter tensors)\n",
    "for name, buf in list(decoder.named_buffers()):\n",
    "    if buf is None:\n",
    "        continue\n",
    "    if buf.ndim == 1 and buf.shape[0] == ORIG_CLASSES:\n",
    "        print(f\"Resizing buffer: {name} shape {buf.shape} -> {TARGET_CLASSES}\")\n",
    "        parent = decoder\n",
    "        parts = name.split('.')\n",
    "        for p in parts[:-1]:\n",
    "            parent = getattr(parent, p)\n",
    "        attr = parts[-1]\n",
    "        # assign as buffer\n",
    "        decoder.register_buffer(attr, torch.zeros(TARGET_CLASSES, dtype=buf.dtype, device=device))\n",
    "        replaced.append(\"buffer:\"+name)\n",
    "\n",
    "print(\"Replaced parameter/buffer names:\", replaced)\n",
    "\n",
    "# 4) move whole glori to device again and do a quick forward test\n",
    "glori_wrapped.to(device)\n",
    "print(\"Moved glori to device.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3faad714",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T09:38:38.312568Z",
     "iopub.status.busy": "2025-10-03T09:38:38.312378Z",
     "iopub.status.idle": "2025-10-03T09:38:38.316474Z",
     "shell.execute_reply": "2025-10-03T09:38:38.315947Z"
    },
    "papermill": {
     "duration": 0.033494,
     "end_time": "2025-10-03T09:38:38.317416",
     "exception": false,
     "start_time": "2025-10-03T09:38:38.283922",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 6) Wrap backbone + new glori into a training model\n",
    "class CheXFoundWithGLoRIHead(nn.Module):\n",
    "    def __init__(self, backbone, glori_module, args):\n",
    "        super().__init__()\n",
    "        self.backbone = backbone\n",
    "        self.glori = glori_module\n",
    "        self.args = args\n",
    "    def forward(self, x):\n",
    "        # get intermediate features and pass to glori\n",
    "        feats = self.backbone.get_intermediate_layers(x, n=self.args.n_last_blocks, return_class_token=self.args.return_class_token)\n",
    "        logits_dict = self.glori([feats], return_attention=False)\n",
    "        key = list(logits_dict.keys())[0]\n",
    "        return logits_dict[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ee869b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T09:38:38.374562Z",
     "iopub.status.busy": "2025-10-03T09:38:38.374362Z",
     "iopub.status.idle": "2025-10-03T09:38:38.862809Z",
     "shell.execute_reply": "2025-10-03T09:38:38.862048Z"
    },
    "papermill": {
     "duration": 0.518236,
     "end_time": "2025-10-03T09:38:38.864257",
     "exception": false,
     "start_time": "2025-10-03T09:38:38.346021",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "\n",
    "cv2.setNumThreads(0)\n",
    "\n",
    "class TestChestXrayDataset(Dataset):\n",
    "    def __init__(self, df, img_dir, transform=None):\n",
    "        self.df = df\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.label_cols = [\n",
    "            \"Atelectasis\",\"Cardiomegaly\",\"Consolidation\",\"Edema\",\n",
    "            \"Enlarged Cardiomediastinum\",\"Fracture\",\"Lung Lesion\",\n",
    "            \"Lung Opacity\",\"No Finding\",\"Pleural Effusion\",\"Pleural Other\",\n",
    "            \"Pneumonia\",\"Pneumothorax\",\"Support Devices\",\n",
    "        ]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_id = row[\"Image_name\"]\n",
    "        img_path = os.path.join(self.img_dir, row[\"Image_name\"])\n",
    "\n",
    "        # Fast read with OpenCV. It may return None if file missing -> handle.\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)\n",
    "        if img is None:\n",
    "            raise FileNotFoundError(f\"Image not found: {img_path}\")\n",
    "\n",
    "        # If grayscale (H, W), convert to 3-channel\n",
    "        if img.ndim == 2:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "        elif img.shape[2] == 4:\n",
    "            # if RGBA, convert to RGB\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGRA2BGR)\n",
    "\n",
    "        # OpenCV loads BGR -> convert to RGB\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=img)\n",
    "            img = augmented[\"image\"]\n",
    "\n",
    "        return img, img_id\n",
    "\n",
    "# choose img_size once\n",
    "img_size = 512\n",
    "size_tuple = (img_size, img_size)   # IMPORTANT: albumentations expects a tuple\n",
    "\n",
    "val_tfms = A.Compose([\n",
    "    A.Resize(height=img_size, width=img_size),   # pass height & width\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b4588dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T09:38:38.922662Z",
     "iopub.status.busy": "2025-10-03T09:38:38.922406Z",
     "iopub.status.idle": "2025-10-03T09:38:38.928807Z",
     "shell.execute_reply": "2025-10-03T09:38:38.928304Z"
    },
    "papermill": {
     "duration": 0.037101,
     "end_time": "2025-10-03T09:38:38.929768",
     "exception": false,
     "start_time": "2025-10-03T09:38:38.892667",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ModelEMA:\n",
    "    def __init__(self, model, decay=0.9997, device=None):\n",
    "        # copy *unwrapped* module (so EMA keys match saved/loaded model keys)\n",
    "        self.decay = decay\n",
    "        self.device = device\n",
    "        self.ema = copy.deepcopy(get_model(model)).eval()\n",
    "        if device is not None:\n",
    "            self.ema.to(device)\n",
    "        for p in self.ema.parameters():\n",
    "            p.requires_grad_(False)\n",
    "\n",
    "    def update(self, model):\n",
    "        src_state = get_model(model).state_dict()\n",
    "        with torch.no_grad():\n",
    "            for k, v in self.ema.state_dict().items():\n",
    "                model_v = src_state[k].detach().to(v.device)\n",
    "                v.copy_(v * self.decay + (1.0 - self.decay) * model_v)\n",
    "\n",
    "    def state_dict(self):\n",
    "        return self.ema.state_dict()\n",
    "\n",
    "\n",
    "def get_model(module):\n",
    "    \"\"\"Return the underlying model (unwrap DataParallel / DDP).\"\"\"\n",
    "    return module.module if hasattr(module, \"module\") else module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09ddae81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T09:38:38.987261Z",
     "iopub.status.busy": "2025-10-03T09:38:38.987051Z",
     "iopub.status.idle": "2025-10-03T09:38:38.994413Z",
     "shell.execute_reply": "2025-10-03T09:38:38.993702Z"
    },
    "papermill": {
     "duration": 0.038044,
     "end_time": "2025-10-03T09:38:38.995426",
     "exception": false,
     "start_time": "2025-10-03T09:38:38.957382",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = GradScaler(device=\"cuda\")\n",
    "\n",
    "def predict_chexfound(dataset,base_model,model_path='', batch_size=128, device=\"cuda\"):\n",
    "    fold_probs = []\n",
    "    all_ids = None\n",
    "    \n",
    "    \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "        \n",
    "        # -----------------------------\n",
    "        # Model: ConvNeXt\n",
    "        # -----------------------------\n",
    "        # -------------------------\n",
    "        \n",
    "        # SAFE unwrap & prepare model for multi-GPU\n",
    "        # -------------------------\n",
    "        print(\"Preparing model on device:\", DEVICE, \"GPUs:\", torch.cuda.device_count())\n",
    "        \n",
    "        # 1) If glori is a DDP wrapper, unwrap to get the real module\n",
    "        glori_wrapped = glori  # original object you loaded\n",
    "        if hasattr(glori_wrapped, \"module\"):\n",
    "            print(\"Unwrapping glori from DDP wrapper -> using glori.module\")\n",
    "            glori_clean = glori_wrapped.module\n",
    "        else:\n",
    "            glori_clean = glori_wrapped\n",
    "        \n",
    "        # move glori_clean to CPU to avoid device mismatch while assembling\n",
    "        glori_clean = glori_clean.cpu()\n",
    "        \n",
    "        # 2) Rebuild train_model with the unwrapped glori (fresh object)\n",
    "        model = CheXFoundWithGLoRIHead(backbone=base_model, glori_module=glori_clean, args=args)\n",
    "        \n",
    "        model = model \n",
    "        checkpoint = torch.load(\n",
    "            model_path,\n",
    "            map_location=\"cpu\",\n",
    "            weights_only=False  \n",
    "        )\n",
    "        model.load_state_dict(checkpoint[\"ema_state_dict\"])\n",
    "\n",
    "        \n",
    "        \n",
    "        # 5) Move model to device\n",
    "        model = model.to(DEVICE)\n",
    "        # 4) If you have multiple GPUs, wrap with nn.DataParallel (NOT DDP)\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            print(\"Wrapping train_model with nn.DataParallel for multi-GPU\")\n",
    "            model = nn.DataParallel(model)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # IMPORTANT: make sure the name used in the rest of your loop refers to the wrapped model\n",
    "        \n",
    "\n",
    "        model.eval()\n",
    "        \n",
    "\n",
    "        fold_out = []\n",
    "        ids = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, img_id in tqdm(loader, desc=f\"Inference Fold \"):\n",
    "                images = images.to(device)\n",
    "                with autocast(device_type=\"cuda\"):\n",
    "                    logits = model(images)\n",
    "                probs = torch.sigmoid(logits)\n",
    "                fold_out.append(probs.cpu())\n",
    "                if all_ids is None:  # only collect IDs once\n",
    "                    ids.extend(img_id)\n",
    "\n",
    "        fold_out = torch.cat(fold_out, dim=0)  # [N, C]\n",
    "        fold_probs.append(fold_out)\n",
    "\n",
    "        if all_ids is None:\n",
    "            all_ids = ids\n",
    "\n",
    "        final_probs = torch.stack(fold_probs, dim=0).mean(0)  # [N, C]\n",
    "        return all_ids, final_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96460ef5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T09:38:39.053775Z",
     "iopub.status.busy": "2025-10-03T09:38:39.053558Z",
     "iopub.status.idle": "2025-10-03T10:51:12.723350Z",
     "shell.execute_reply": "2025-10-03T10:51:12.722538Z"
    },
    "papermill": {
     "duration": 4353.699521,
     "end_time": "2025-10-03T10:51:12.724695",
     "exception": false,
     "start_time": "2025-10-03T09:38:39.025174",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing model on device: cuda GPUs: 2\n",
      "Unwrapping glori from DDP wrapper -> using glori.module\n",
      "Wrapping train_model with nn.DataParallel for multi-GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Fold : 100%|██████████| 723/723 [1:12:24<00:00,  6.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Submission file saved with correct format\n"
     ]
    }
   ],
   "source": [
    "test_dataset = TestChestXrayDataset(\n",
    "    df=test_df,\n",
    "    img_dir=test_images_folder,\n",
    "    transform=val_tfms\n",
    ")\n",
    "all_ids,final_probs = predict_chexfound(test_dataset,base_model,model_path=f'{chexfound_folder_path}/CheXFound/ema_model_f5.pth', batch_size=64, device=DEVICE)\n",
    "\n",
    "\n",
    "\n",
    "all_preds = np.vstack(final_probs)\n",
    "\n",
    "# -----------------------------\n",
    "# Build Submission\n",
    "# -----------------------------\n",
    "sample_df = test_df\n",
    "\n",
    "submission_chexfound_ep5 = pd.DataFrame(all_preds, columns=labels_cols)\n",
    "submission_chexfound_ep5.insert(0, \"Image_name\", all_ids)\n",
    "\n",
    "# 🔒 Align with sample submission\n",
    "submission_chexfound_ep5 = submission_chexfound_ep5[sample_df.columns]\n",
    "\n",
    "# assert submission_chexfound_ep5.shape == sample_df.shape, \"Shape mismatch with sample submission!\"\n",
    "# assert all(submission_chexfound_ep5[\"Image_name\"] == sample_df[\"Image_name\"]), \"Image names mismatch!\"\n",
    "\n",
    "# submission_chexfound_ep5.to_csv(\"submission_chexfound_ep5.csv\", index=False)\n",
    "# print(\"✅ Submission file saved with correct format\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce2a2a2",
   "metadata": {
    "papermill": {
     "duration": 0.055862,
     "end_time": "2025-10-03T10:51:12.977392",
     "exception": false,
     "start_time": "2025-10-03T10:51:12.921530",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83199940",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T10:51:13.090221Z",
     "iopub.status.busy": "2025-10-03T10:51:13.089612Z",
     "iopub.status.idle": "2025-10-03T12:03:37.638406Z",
     "shell.execute_reply": "2025-10-03T12:03:37.637609Z"
    },
    "papermill": {
     "duration": 4344.606541,
     "end_time": "2025-10-03T12:03:37.639817",
     "exception": false,
     "start_time": "2025-10-03T10:51:13.033276",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing model on device: cuda GPUs: 2\n",
      "Unwrapping glori from DDP wrapper -> using glori.module\n",
      "Wrapping train_model with nn.DataParallel for multi-GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Fold : 100%|██████████| 723/723 [1:12:15<00:00,  6.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Submission file saved with correct format\n"
     ]
    }
   ],
   "source": [
    "test_dataset = TestChestXrayDataset(\n",
    "    df=test_df,\n",
    "    img_dir=test_images_folder,\n",
    "    transform=val_tfms\n",
    ")\n",
    "all_ids,final_probs = predict_chexfound(test_dataset,base_model,model_path=f'{chexfound_folder_path}/CheXFound/ema_model_f6.pth', batch_size=64, device=DEVICE)\n",
    "\n",
    "\n",
    "all_preds = np.vstack(final_probs)\n",
    "\n",
    "# -----------------------------\n",
    "# Build Submission\n",
    "# -----------------------------\n",
    "sample_df = test_df\n",
    "\n",
    "submission_chexfound_ep6 = pd.DataFrame(all_preds, columns=labels_cols)\n",
    "submission_chexfound_ep6.insert(0, \"Image_name\", all_ids)\n",
    "\n",
    "# 🔒 Align with sample submission\n",
    "submission_chexfound_ep6 = submission_chexfound_ep6[sample_df.columns]\n",
    "\n",
    "# assert submission_chexfound_ep6.shape == sample_df.shape, \"Shape mismatch with sample submission!\"\n",
    "# assert all(submission_chexfound_ep6[\"Image_name\"] == sample_df[\"Image_name\"]), \"Image names mismatch!\"\n",
    "\n",
    "# submission_chexfound_ep6.to_csv(\"submission_chexfound_ep6.csv\", index=False)\n",
    "# print(\"✅ Submission file saved with correct format\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "689be7fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T12:03:38.002984Z",
     "iopub.status.busy": "2025-10-03T12:03:38.002754Z",
     "iopub.status.idle": "2025-10-03T12:03:38.122295Z",
     "shell.execute_reply": "2025-10-03T12:03:38.121811Z"
    },
    "papermill": {
     "duration": 0.206381,
     "end_time": "2025-10-03T12:03:38.123430",
     "exception": false,
     "start_time": "2025-10-03T12:03:37.917049",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6abd7eb",
   "metadata": {
    "papermill": {
     "duration": 0.137937,
     "end_time": "2025-10-03T12:03:38.344956",
     "exception": false,
     "start_time": "2025-10-03T12:03:38.207019",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# evax 448"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b4d91568",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T12:03:38.520009Z",
     "iopub.status.busy": "2025-10-03T12:03:38.519501Z",
     "iopub.status.idle": "2025-10-03T12:03:38.532301Z",
     "shell.execute_reply": "2025-10-03T12:03:38.531784Z"
    },
    "papermill": {
     "duration": 0.100068,
     "end_time": "2025-10-03T12:03:38.533345",
     "exception": false,
     "start_time": "2025-10-03T12:03:38.433277",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def checkpoint_filter_fn(\n",
    "        state_dict,\n",
    "        model,\n",
    "        interpolation='bicubic',\n",
    "        antialias=True,\n",
    "):\n",
    "    \"\"\" convert patch embedding weight from manual patchify + linear proj to conv\"\"\"\n",
    "    out_dict = {}\n",
    "    state_dict = state_dict.get('model_ema', state_dict)\n",
    "    state_dict = state_dict.get('model', state_dict)\n",
    "    state_dict = state_dict.get('module', state_dict)\n",
    "    state_dict = state_dict.get('state_dict', state_dict)\n",
    "    # prefix for loading OpenCLIP compatible weights\n",
    "    if 'visual.trunk.pos_embed' in state_dict:\n",
    "        prefix = 'visual.trunk.'\n",
    "    elif 'visual.pos_embed' in state_dict:\n",
    "        prefix = 'visual.'\n",
    "    else:\n",
    "        prefix = ''\n",
    "    mim_weights = prefix + 'mask_token' in state_dict\n",
    "    no_qkv = prefix + 'blocks.0.attn.q_proj.weight' in state_dict\n",
    "\n",
    "    len_prefix = len(prefix)\n",
    "    for k, v in state_dict.items():\n",
    "        if prefix:\n",
    "            if k.startswith(prefix):\n",
    "                k = k[len_prefix:]\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        if 'rope' in k:\n",
    "            # fixed embedding no need to load buffer from checkpoint\n",
    "            continue\n",
    "\n",
    "        if 'patch_embed.proj.weight' in k:\n",
    "            _, _, H, W = model.patch_embed.proj.weight.shape\n",
    "            if v.shape[-1] != W or v.shape[-2] != H:\n",
    "                v = resample_patch_embed(\n",
    "                    v,\n",
    "                    (H, W),\n",
    "                    interpolation=interpolation,\n",
    "                    antialias=antialias,\n",
    "                    verbose=True,\n",
    "                )\n",
    "        elif k == 'pos_embed' and v.shape[1] != model.pos_embed.shape[1]:\n",
    "            # To resize pos embedding when using model at different size from pretrained weights\n",
    "            num_prefix_tokens = 0 if getattr(model, 'no_embed_class', False) else getattr(model, 'num_prefix_tokens', 1)\n",
    "            v = resample_abs_pos_embed(\n",
    "                v,\n",
    "                new_size=model.patch_embed.grid_size,\n",
    "                num_prefix_tokens=num_prefix_tokens,\n",
    "                interpolation=interpolation,\n",
    "                antialias=antialias,\n",
    "                verbose=True,\n",
    "            )\n",
    "\n",
    "        k = k.replace('mlp.ffn_ln', 'mlp.norm')\n",
    "        k = k.replace('attn.inner_attn_ln', 'attn.norm')\n",
    "        k = k.replace('mlp.w12', 'mlp.fc1')\n",
    "        k = k.replace('mlp.w1', 'mlp.fc1_g')\n",
    "        k = k.replace('mlp.w2', 'mlp.fc1_x')\n",
    "        k = k.replace('mlp.w3', 'mlp.fc2')\n",
    "        if no_qkv:\n",
    "            k = k.replace('q_bias', 'q_proj.bias')\n",
    "            k = k.replace('v_bias', 'v_proj.bias')\n",
    "\n",
    "        if mim_weights and k in ('mask_token', 'lm_head.weight', 'lm_head.bias', 'norm.weight', 'norm.bias'):\n",
    "            if k == 'norm.weight' or k == 'norm.bias':\n",
    "                # try moving norm -> fc norm on fine-tune, probably a better starting point than new init\n",
    "                k = k.replace('norm', 'fc_norm')\n",
    "            else:\n",
    "                # skip pretrain mask token & head weights\n",
    "                continue\n",
    "\n",
    "        out_dict[k] = v\n",
    "\n",
    "    return out_dict\n",
    "\n",
    "class EVA_X(Eva):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(EVA_X, self).__init__(**kwargs)\n",
    "\n",
    "    def forward_features(self, x):\n",
    "        x = self.patch_embed(x)\n",
    "        x, rot_pos_embed = self._pos_embed(x)\n",
    "        for blk in self.blocks:\n",
    "            x = blk(x, rope=rot_pos_embed)\n",
    "        x = self.norm(x)\n",
    "        return x\n",
    "\n",
    "    def forward_head(self, x, pre_logits: bool = False):\n",
    "        if self.global_pool:\n",
    "            x = x[:, self.num_prefix_tokens:].mean(dim=1) if self.global_pool == 'avg' else x[:, 0]\n",
    "        x = self.fc_norm(x)\n",
    "        x = self.head_drop(x)\n",
    "        return x if pre_logits else self.head(x)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.forward_features(x)\n",
    "        x = self.forward_head(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def eva_x_base_patch16(pretrained=False):\n",
    "    model = EVA_X(\n",
    "        img_size=img_size,\n",
    "        patch_size=16,\n",
    "        embed_dim=768,\n",
    "        depth=12,\n",
    "        num_heads=12,\n",
    "        qkv_fused=False,\n",
    "        mlp_ratio=4 * 2 / 3,\n",
    "        swiglu_mlp=True,\n",
    "        scale_mlp=True,\n",
    "        use_rot_pos_emb=True,\n",
    "        ref_feat_shape=(14, 14),  # 224/16\n",
    "    )\n",
    "    eva_ckpt = checkpoint_filter_fn(torch.load(pretrained, map_location='cpu', weights_only=False), \n",
    "                        model)\n",
    "    msg = model.load_state_dict(eva_ckpt, strict=False)\n",
    "    print(msg)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8c394750",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T12:03:38.705160Z",
     "iopub.status.busy": "2025-10-03T12:03:38.704579Z",
     "iopub.status.idle": "2025-10-03T12:03:38.709133Z",
     "shell.execute_reply": "2025-10-03T12:03:38.708597Z"
    },
    "papermill": {
     "duration": 0.091435,
     "end_time": "2025-10-03T12:03:38.710219",
     "exception": false,
     "start_time": "2025-10-03T12:03:38.618784",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#evax base\n",
    "class EVAX_Model(nn.Module):\n",
    "    def __init__(self, unfreeze_last_n_blocks=4 ):\n",
    "        super().__init__()\n",
    "        # Load Phikon backbone\n",
    "        eva_x_b_pt = '/kaggle/input/evax-recs-448-div-a/eva_x_base_patch16_merged520k_mim.pt'  \n",
    "        self.backbone = eva_x_base_patch16(pretrained=eva_x_b_pt)\n",
    "        \n",
    "        self.backbone.head=nn.Linear(in_features=768, out_features=14, bias=True)\n",
    "\n",
    "        # # Also unfreeze head and normalisation layers around it\n",
    "        for p in self.backbone.head.parameters():\n",
    "            p.requires_grad = True\n",
    "\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        backbone_output = self.backbone(x)\n",
    "    \n",
    "        #return self.head(backbone_output)\n",
    "        return backbone_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c20080a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T12:03:38.879404Z",
     "iopub.status.busy": "2025-10-03T12:03:38.878634Z",
     "iopub.status.idle": "2025-10-03T12:03:38.890911Z",
     "shell.execute_reply": "2025-10-03T12:03:38.890392Z"
    },
    "papermill": {
     "duration": 0.097369,
     "end_time": "2025-10-03T12:03:38.891982",
     "exception": false,
     "start_time": "2025-10-03T12:03:38.794613",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_size = 448\n",
    "\n",
    "normalize = A.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                        std=[0.229, 0.224, 0.225])\n",
    "\n",
    "def scale_brightness(factor):\n",
    "    def apply_fn(x, **kwargs):\n",
    "        return (x * factor).clip(0, 255).astype(x.dtype)\n",
    "    return apply_fn\n",
    "\n",
    "tta_transforms = [\n",
    "\n",
    "    # 1. Original\n",
    "    A.Compose([\n",
    "        A.Resize(img_size, img_size),\n",
    "        normalize,\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "\n",
    "    # 2. Horizontal Flip\n",
    "    A.Compose([\n",
    "        A.HorizontalFlip(p=1.0),\n",
    "        A.Resize(img_size, img_size),\n",
    "        normalize,\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "\n",
    "    # 3–5. Multi-scale center crops (zoom in/out)\n",
    "    *[\n",
    "        A.Compose([\n",
    "            A.Resize(int(img_size * scale), int(img_size * scale)),\n",
    "            A.CenterCrop(img_size, img_size),\n",
    "            normalize,\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "        #for scale in [0.9, 1.0, 1.1]\n",
    "        for scale in [1.0, 1.1]\n",
    "    ],\n",
    "\n",
    "    # 6–7. Brightness scaling\n",
    "    A.Compose([\n",
    "        A.Resize(img_size, img_size),\n",
    "        A.Lambda(image=scale_brightness(0.95)),\n",
    "        normalize,\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "    A.Compose([\n",
    "        A.Resize(img_size, img_size),\n",
    "        A.Lambda(image=scale_brightness(1.05)),\n",
    "        normalize,\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "043f0cd8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T12:03:39.061570Z",
     "iopub.status.busy": "2025-10-03T12:03:39.061374Z",
     "iopub.status.idle": "2025-10-03T12:03:39.068248Z",
     "shell.execute_reply": "2025-10-03T12:03:39.067702Z"
    },
    "papermill": {
     "duration": 0.092946,
     "end_time": "2025-10-03T12:03:39.069297",
     "exception": false,
     "start_time": "2025-10-03T12:03:38.976351",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = GradScaler(device=\"cuda\")\n",
    "\n",
    "def predict_tta(dataset, tta_transforms, model_path='', batch_size=128, device=\"cuda\"):\n",
    "    fold_probs = []\n",
    "    all_ids = None\n",
    "    \n",
    "    #k=1\n",
    "\n",
    "    # -----------------------------\n",
    "    # Model: ConvNeXt\n",
    "    # -----------------------------\n",
    "    model = EVAX_Model()\n",
    "    checkpoint = torch.load(\n",
    "        model_path,\n",
    "        map_location=\"cpu\",\n",
    "        weights_only=False  \n",
    "    )\n",
    "    model.load_state_dict(checkpoint[\"ema_state_dict\"])\n",
    "    \n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(f\"⚡ Using {torch.cuda.device_count()} GPUs\")\n",
    "        model = nn.DataParallel(model)  # wrap for multi-GPU\n",
    "    \n",
    "    model = model.to(DEVICE)\n",
    "    \n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "\n",
    "    ids = []\n",
    "    \n",
    "    for tfm in tta_transforms:\n",
    "        dataset.transform = tfm \n",
    "        loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "        \n",
    "        fold_out = []\n",
    "        with torch.no_grad():\n",
    "            for images, img_id in tqdm(loader, desc=f\"Inference\"):\n",
    "                \n",
    "                images = images.to(device)\n",
    "                with autocast(device_type=\"cuda\"):\n",
    "                    logits = model(images)\n",
    "                probs = torch.sigmoid(logits)\n",
    "                fold_out.append(probs.cpu())\n",
    "                if all_ids is None:  # only collect IDs once\n",
    "                    ids.extend(img_id)\n",
    "\n",
    "        fold_out = torch.cat(fold_out, dim=0)  # [N, C]\n",
    "        fold_probs.append(fold_out)\n",
    "\n",
    "        if all_ids is None:\n",
    "            all_ids = ids\n",
    "\n",
    "    final_probs = torch.stack(fold_probs, dim=0).mean(0)  # [N, C]\n",
    "    return all_ids, final_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594ad004",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T12:03:39.237682Z",
     "iopub.status.busy": "2025-10-03T12:03:39.237233Z",
     "iopub.status.idle": "2025-10-03T13:53:47.907647Z",
     "shell.execute_reply": "2025-10-03T13:53:47.906633Z"
    },
    "papermill": {
     "duration": 6608.755922,
     "end_time": "2025-10-03T13:53:47.909232",
     "exception": false,
     "start_time": "2025-10-03T12:03:39.153310",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I20251003 12:03:47 19 timm.layers.pos_embed pos_embed.py:57] Resized position embedding: (14, 14) to (28, 28).\n",
      "_IncompatibleKeys(missing_keys=['head.weight', 'head.bias'], unexpected_keys=[])\n",
      "⚡ Using 2 GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 100%|██████████| 362/362 [18:23<00:00,  3.05s/it]\n",
      "Inference: 100%|██████████| 362/362 [18:19<00:00,  3.04s/it]\n",
      "Inference: 100%|██████████| 362/362 [18:17<00:00,  3.03s/it]\n",
      "Inference: 100%|██████████| 362/362 [18:16<00:00,  3.03s/it]\n",
      "Inference: 100%|██████████| 362/362 [18:18<00:00,  3.04s/it]\n",
      "Inference: 100%|██████████| 362/362 [18:19<00:00,  3.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Submission file saved with correct format\n"
     ]
    }
   ],
   "source": [
    "test_dataset = TestChestXrayDataset(\n",
    "    df=test_df,\n",
    "    img_dir=test_images_folder,\n",
    "    transform=None\n",
    ")\n",
    "all_ids,final_probs = predict_tta(test_dataset, tta_transforms, model_path=f'{evax448_folder_path_ep5}/ema_model_f5.pth', batch_size=128, device=DEVICE)\n",
    "\n",
    "all_preds = np.vstack(final_probs)\n",
    "# -----------------------------\n",
    "# Build Submission\n",
    "# -----------------------------\n",
    "sample_df = test_df\n",
    "\n",
    "submission_evax448_ep5 = pd.DataFrame(all_preds, columns=labels_cols)\n",
    "submission_evax448_ep5.insert(0, \"Image_name\", all_ids)\n",
    "\n",
    "# 🔒 Align with sample submission\n",
    "submission_evax448_ep5 = submission_evax448_ep5[sample_df.columns]\n",
    "\n",
    "# assert submission_evax448_ep5.shape == sample_df.shape, \"Shape mismatch with sample submission!\"\n",
    "#assert all(submission_evax448_ep5[\"Image_name\"] == sample_df[\"Image_name\"]), \"Image names mismatch!\"\n",
    "\n",
    "# submission_evax448_ep5.to_csv(\"submission_evax448_ep5.csv\", index=False)\n",
    "# print(\"✅ Submission file saved with correct format\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0475b49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T13:53:48.701793Z",
     "iopub.status.busy": "2025-10-03T13:53:48.701527Z",
     "iopub.status.idle": "2025-10-03T15:43:54.032630Z",
     "shell.execute_reply": "2025-10-03T15:43:54.031666Z"
    },
    "papermill": {
     "duration": 6605.510447,
     "end_time": "2025-10-03T15:43:54.034042",
     "exception": false,
     "start_time": "2025-10-03T13:53:48.523595",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I20251003 13:53:50 19 timm.layers.pos_embed pos_embed.py:57] Resized position embedding: (14, 14) to (28, 28).\n",
      "_IncompatibleKeys(missing_keys=['head.weight', 'head.bias'], unexpected_keys=[])\n",
      "⚡ Using 2 GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 100%|██████████| 362/362 [18:20<00:00,  3.04s/it]\n",
      "Inference: 100%|██████████| 362/362 [18:19<00:00,  3.04s/it]\n",
      "Inference: 100%|██████████| 362/362 [18:19<00:00,  3.04s/it]\n",
      "Inference: 100%|██████████| 362/362 [18:18<00:00,  3.04s/it]\n",
      "Inference: 100%|██████████| 362/362 [18:20<00:00,  3.04s/it]\n",
      "Inference: 100%|██████████| 362/362 [18:19<00:00,  3.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Submission file saved with correct format\n"
     ]
    }
   ],
   "source": [
    "test_dataset = TestChestXrayDataset(\n",
    "    df=test_df,\n",
    "    img_dir=test_images_folder,\n",
    "    transform=None\n",
    ")\n",
    "all_ids,final_probs = predict_tta(test_dataset, tta_transforms, model_path=f'{evax448_folder_path_ep6}/ema_model_f6.pth', batch_size=128, device=DEVICE)\n",
    "\n",
    "all_preds = np.vstack(final_probs)\n",
    "# -----------------------------\n",
    "# Build Submission\n",
    "# -----------------------------\n",
    "sample_df = test_df\n",
    "\n",
    "submission_evax448_ep6 = pd.DataFrame(all_preds, columns=labels_cols)\n",
    "submission_evax448_ep6.insert(0, \"Image_name\", all_ids)\n",
    "\n",
    "# 🔒 Align with sample submission\n",
    "submission_evax448_ep6 = submission_evax448_ep6[sample_df.columns]\n",
    "\n",
    "# assert submission_evax448_ep6.shape == sample_df.shape, \"Shape mismatch with sample submission!\"\n",
    "# assert all(submission_evax448_ep6[\"Image_name\"] == sample_df[\"Image_name\"]), \"Image names mismatch!\"\n",
    "\n",
    "# submission_evax448_ep6.to_csv(\"submission_evax448_ep6.csv\", index=False)\n",
    "# print(\"✅ Submission file saved with correct format\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8876a0ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T15:43:55.098225Z",
     "iopub.status.busy": "2025-10-03T15:43:55.097951Z",
     "iopub.status.idle": "2025-10-03T15:43:55.165081Z",
     "shell.execute_reply": "2025-10-03T15:43:55.164523Z"
    },
    "papermill": {
     "duration": 0.325954,
     "end_time": "2025-10-03T15:43:55.166302",
     "exception": false,
     "start_time": "2025-10-03T15:43:54.840348",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468af4d8",
   "metadata": {
    "papermill": {
     "duration": 0.705844,
     "end_time": "2025-10-03T18:09:22.099666",
     "exception": false,
     "start_time": "2025-10-03T18:09:21.393822",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b87b30e5",
   "metadata": {
    "papermill": {
     "duration": 0.874069,
     "end_time": "2025-10-03T18:09:23.682608",
     "exception": false,
     "start_time": "2025-10-03T18:09:22.808539",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4afea97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T18:09:25.117848Z",
     "iopub.status.busy": "2025-10-03T18:09:25.117263Z",
     "iopub.status.idle": "2025-10-03T18:09:25.838025Z",
     "shell.execute_reply": "2025-10-03T18:09:25.837197Z"
    },
    "papermill": {
     "duration": 1.44562,
     "end_time": "2025-10-03T18:09:25.839203",
     "exception": false,
     "start_time": "2025-10-03T18:09:24.393583",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Averaged submission saved as submission_avg.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image_name</th>\n",
       "      <th>Atelectasis</th>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Enlarged Cardiomediastinum</th>\n",
       "      <th>Fracture</th>\n",
       "      <th>Lung Lesion</th>\n",
       "      <th>Lung Opacity</th>\n",
       "      <th>No Finding</th>\n",
       "      <th>Pleural Effusion</th>\n",
       "      <th>Pleural Other</th>\n",
       "      <th>Pneumonia</th>\n",
       "      <th>Pneumothorax</th>\n",
       "      <th>Support Devices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000005_001_001.jpg</td>\n",
       "      <td>0.030375</td>\n",
       "      <td>0.015293</td>\n",
       "      <td>0.028139</td>\n",
       "      <td>0.004315</td>\n",
       "      <td>0.073627</td>\n",
       "      <td>0.229224</td>\n",
       "      <td>0.451947</td>\n",
       "      <td>0.090495</td>\n",
       "      <td>0.266503</td>\n",
       "      <td>0.016917</td>\n",
       "      <td>0.184173</td>\n",
       "      <td>0.092054</td>\n",
       "      <td>0.079244</td>\n",
       "      <td>0.558647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00000005_001_002.jpg</td>\n",
       "      <td>0.032489</td>\n",
       "      <td>0.012623</td>\n",
       "      <td>0.021773</td>\n",
       "      <td>0.004879</td>\n",
       "      <td>0.058231</td>\n",
       "      <td>0.210948</td>\n",
       "      <td>0.168526</td>\n",
       "      <td>0.064428</td>\n",
       "      <td>0.133910</td>\n",
       "      <td>0.018425</td>\n",
       "      <td>0.180720</td>\n",
       "      <td>0.056841</td>\n",
       "      <td>0.031499</td>\n",
       "      <td>0.770428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00000005_002_001.jpg</td>\n",
       "      <td>0.948211</td>\n",
       "      <td>0.575407</td>\n",
       "      <td>0.815825</td>\n",
       "      <td>0.299159</td>\n",
       "      <td>0.764707</td>\n",
       "      <td>0.771013</td>\n",
       "      <td>0.238251</td>\n",
       "      <td>0.968124</td>\n",
       "      <td>0.002412</td>\n",
       "      <td>0.828460</td>\n",
       "      <td>0.324162</td>\n",
       "      <td>0.635403</td>\n",
       "      <td>0.522942</td>\n",
       "      <td>0.731586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00000005_002_002.jpg</td>\n",
       "      <td>0.930789</td>\n",
       "      <td>0.389242</td>\n",
       "      <td>0.792743</td>\n",
       "      <td>0.110524</td>\n",
       "      <td>0.540091</td>\n",
       "      <td>0.769654</td>\n",
       "      <td>0.239183</td>\n",
       "      <td>0.944625</td>\n",
       "      <td>0.003939</td>\n",
       "      <td>0.814814</td>\n",
       "      <td>0.405391</td>\n",
       "      <td>0.675041</td>\n",
       "      <td>0.628285</td>\n",
       "      <td>0.780554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00000007_001_001.jpg</td>\n",
       "      <td>0.201538</td>\n",
       "      <td>0.172781</td>\n",
       "      <td>0.082128</td>\n",
       "      <td>0.138857</td>\n",
       "      <td>0.325716</td>\n",
       "      <td>0.049504</td>\n",
       "      <td>0.018223</td>\n",
       "      <td>0.287394</td>\n",
       "      <td>0.073225</td>\n",
       "      <td>0.046929</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>0.032417</td>\n",
       "      <td>0.150414</td>\n",
       "      <td>0.817990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Image_name  Atelectasis  Cardiomegaly  Consolidation     Edema  \\\n",
       "0  00000005_001_001.jpg     0.030375      0.015293       0.028139  0.004315   \n",
       "1  00000005_001_002.jpg     0.032489      0.012623       0.021773  0.004879   \n",
       "2  00000005_002_001.jpg     0.948211      0.575407       0.815825  0.299159   \n",
       "3  00000005_002_002.jpg     0.930789      0.389242       0.792743  0.110524   \n",
       "4  00000007_001_001.jpg     0.201538      0.172781       0.082128  0.138857   \n",
       "\n",
       "   Enlarged Cardiomediastinum  Fracture  Lung Lesion  Lung Opacity  \\\n",
       "0                    0.073627  0.229224     0.451947      0.090495   \n",
       "1                    0.058231  0.210948     0.168526      0.064428   \n",
       "2                    0.764707  0.771013     0.238251      0.968124   \n",
       "3                    0.540091  0.769654     0.239183      0.944625   \n",
       "4                    0.325716  0.049504     0.018223      0.287394   \n",
       "\n",
       "   No Finding  Pleural Effusion  Pleural Other  Pneumonia  Pneumothorax  \\\n",
       "0    0.266503          0.016917       0.184173   0.092054      0.079244   \n",
       "1    0.133910          0.018425       0.180720   0.056841      0.031499   \n",
       "2    0.002412          0.828460       0.324162   0.635403      0.522942   \n",
       "3    0.003939          0.814814       0.405391   0.675041      0.628285   \n",
       "4    0.073225          0.046929       0.005500   0.032417      0.150414   \n",
       "\n",
       "   Support Devices  \n",
       "0         0.558647  \n",
       "1         0.770428  \n",
       "2         0.731586  \n",
       "3         0.780554  \n",
       "4         0.817990  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# submission_chexfound_ep5 \n",
    "# submission_chexfound_ep6 \n",
    "# submission_evax448_ep5 \n",
    "# submission_evax448_ep6 \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Average predictions (excluding Image_name)\n",
    "avg_sub = submission_chexfound_ep5.copy()\n",
    "\n",
    "#just chexfound and evax 448\n",
    "avg_sub.iloc[:, 1:] = (submission_chexfound_ep5.iloc[:, 1:]+submission_chexfound_ep6.iloc[:, 1:] + submission_evax448_ep5.iloc[:, 1:] + submission_evax448_ep6.iloc[:, 1:]) / 4\n",
    "\n",
    "# Save new submission\n",
    "avg_sub.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(\"✅ Averaged submission saved as submission_avg.csv\")\n",
    "avg_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306f8001",
   "metadata": {
    "papermill": {
     "duration": 0.694796,
     "end_time": "2025-10-03T18:09:27.393933",
     "exception": false,
     "start_time": "2025-10-03T18:09:26.699137",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 13449579,
     "sourceId": 112899,
     "sourceType": "competition"
    },
    {
     "datasetId": 8304094,
     "sourceId": 13109235,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8388907,
     "sourceId": 13238085,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 263800546,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 263805598,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 30779.023733,
   "end_time": "2025-10-03T18:09:33.852722",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-10-03T09:36:34.828989",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
