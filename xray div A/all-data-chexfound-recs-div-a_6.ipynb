{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06360f03",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-10-01T10:05:04.674223Z",
     "iopub.status.busy": "2025-10-01T10:05:04.673968Z",
     "iopub.status.idle": "2025-10-01T10:06:47.140355Z",
     "shell.execute_reply": "2025-10-01T10:06:47.139383Z"
    },
    "papermill": {
     "duration": 102.472702,
     "end_time": "2025-10-01T10:06:47.141811",
     "exception": false,
     "start_time": "2025-10-01T10:05:04.669109",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fvcore\r\n",
      "  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from fvcore) (1.26.4)\r\n",
      "Collecting yacs>=0.1.6 (from fvcore)\r\n",
      "  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from fvcore) (6.0.2)\r\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from fvcore) (4.67.1)\r\n",
      "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.11/dist-packages (from fvcore) (3.1.0)\r\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from fvcore) (11.2.1)\r\n",
      "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from fvcore) (0.9.0)\r\n",
      "Collecting iopath>=0.1.7 (from fvcore)\r\n",
      "  Downloading iopath-0.1.10.tar.gz (42 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from iopath>=0.1.7->fvcore) (4.14.0)\r\n",
      "Collecting portalocker (from iopath>=0.1.7->fvcore)\r\n",
      "  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->fvcore) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->fvcore) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->fvcore) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->fvcore) (2025.2.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->fvcore) (2022.2.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->fvcore) (2.4.1)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->fvcore) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->fvcore) (2022.2.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->fvcore) (1.4.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->fvcore) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->fvcore) (2024.2.0)\r\n",
      "Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\r\n",
      "Downloading portalocker-3.2.0-py3-none-any.whl (22 kB)\r\n",
      "Building wheels for collected packages: fvcore, iopath\r\n",
      "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61397 sha256=e7607b24d92d657478820c8dfef6e3b3cbcc63cb9050d78efce0958a0815dafd\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/65/71/95/3b8fde5c65c6e4a806e0867c1651dcc71a1cb2f3430e8f355f\r\n",
      "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31527 sha256=bf9c9bcdeb2cb93e839f53d6dd79bbc3b50ec53a9437836097090a719ef9ab84\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/ba/5e/16/6117f8fe7e9c0c161a795e10d94645ebcf301ccbd01f66d8ec\r\n",
      "Successfully built fvcore iopath\r\n",
      "Installing collected packages: yacs, portalocker, iopath, fvcore\r\n",
      "Successfully installed fvcore-0.1.5.post20221221 iopath-0.1.10 portalocker-3.2.0 yacs-0.1.8\r\n",
      "Collecting open_clip_torch\r\n",
      "  Downloading open_clip_torch-3.2.0-py3-none-any.whl.metadata (32 kB)\r\n",
      "Requirement already satisfied: torch>=2.0 in /usr/local/lib/python3.11/dist-packages (from open_clip_torch) (2.6.0+cu124)\r\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from open_clip_torch) (0.21.0+cu124)\r\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from open_clip_torch) (2024.11.6)\r\n",
      "Collecting ftfy (from open_clip_torch)\r\n",
      "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\r\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from open_clip_torch) (4.67.1)\r\n",
      "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/dist-packages (from open_clip_torch) (0.33.1)\r\n",
      "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from open_clip_torch) (0.5.3)\r\n",
      "Collecting timm>=1.0.17 (from open_clip_torch)\r\n",
      "  Downloading timm-1.0.20-py3-none-any.whl.metadata (61 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.7/61.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from timm>=1.0.17->open_clip_torch) (6.0.2)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->open_clip_torch) (3.18.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->open_clip_torch) (4.14.0)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->open_clip_torch) (3.5)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->open_clip_torch) (3.1.6)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->open_clip_torch) (2025.5.1)\r\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0->open_clip_torch)\r\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0->open_clip_torch)\r\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0->open_clip_torch)\r\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0->open_clip_torch)\r\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0->open_clip_torch)\r\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0->open_clip_torch)\r\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0->open_clip_torch)\r\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0->open_clip_torch)\r\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0->open_clip_torch)\r\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->open_clip_torch) (0.6.2)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->open_clip_torch) (2.21.5)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->open_clip_torch) (12.4.127)\r\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0->open_clip_torch)\r\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->open_clip_torch) (3.2.0)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->open_clip_torch) (1.13.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0->open_clip_torch) (1.3.0)\r\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy->open_clip_torch) (0.2.13)\r\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->open_clip_torch) (25.0)\r\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->open_clip_torch) (2.32.4)\r\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->open_clip_torch) (1.1.5)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision->open_clip_torch) (1.26.4)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->open_clip_torch) (11.2.1)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0->open_clip_torch) (3.0.2)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->open_clip_torch) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->open_clip_torch) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->open_clip_torch) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->open_clip_torch) (2025.2.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->open_clip_torch) (2022.2.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->open_clip_torch) (2.4.1)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->open_clip_torch) (3.4.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->open_clip_torch) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->open_clip_torch) (2.5.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->open_clip_torch) (2025.6.15)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision->open_clip_torch) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision->open_clip_torch) (2022.2.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torchvision->open_clip_torch) (1.4.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torchvision->open_clip_torch) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torchvision->open_clip_torch) (2024.2.0)\r\n",
      "Downloading open_clip_torch-3.2.0-py3-none-any.whl (1.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading timm-1.0.20-py3-none-any.whl (2.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m70.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m95.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m68.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))': /packages/ff/ff/847841bacfbefc97a00036e0fce5a0f086b640756dc38caea5e1bb002655/nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl\u001b[0m\u001b[33m\r\n",
      "\u001b[0mDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m75.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading ftfy-6.3.1-py3-none-any.whl (44 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ftfy, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, timm, open_clip_torch\r\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\r\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-curand-cu12\r\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\r\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\r\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\r\n",
      "  Attempting uninstall: nvidia-cufft-cu12\r\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\r\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\r\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\r\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\r\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\r\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\r\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cublas-cu12\r\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\r\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\r\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\r\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\r\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\r\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\r\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\r\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\r\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\r\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\r\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\r\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\r\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\r\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\r\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\r\n",
      "  Attempting uninstall: timm\r\n",
      "    Found existing installation: timm 1.0.15\r\n",
      "    Uninstalling timm-1.0.15:\r\n",
      "      Successfully uninstalled timm-1.0.15\r\n",
      "Successfully installed ftfy-6.3.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 open_clip_torch-3.2.0 timm-1.0.20\r\n",
      "Cloning into '/kaggle/working/CheXFound'...\r\n",
      "remote: Enumerating objects: 457, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (457/457), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (355/355), done.\u001b[K\r\n",
      "remote: Total 457 (delta 133), reused 407 (delta 96), pack-reused 0 (from 0)\u001b[K\r\n",
      "Receiving objects: 100% (457/457), 24.14 MiB | 38.50 MiB/s, done.\r\n",
      "Resolving deltas: 100% (133/133), done.\r\n",
      "Retrieving folder contents\r\n",
      "Processing file 1nd2OA6kPgaDO_SuYrbobSyQtofD2XIHW config.yaml\r\n",
      "Processing file 1i-cBIp0_jV4SRDrt4n1re5QVRUTAAUBQ glori.pth\r\n",
      "Processing file 1K9EJ9SKBkKx9eTGVOojdkkBfPRcPM6Ak results_eval_linear.json\r\n",
      "Processing file 1qvbxNIVhTiUWwAnOYy83I8ZX7s__FaMQ teacher_checkpoint.pth\r\n",
      "Retrieving folder contents completed\r\n",
      "Building directory structure\r\n",
      "Building directory structure completed\r\n",
      "Downloading...\r\n",
      "From: https://drive.google.com/uc?id=1nd2OA6kPgaDO_SuYrbobSyQtofD2XIHW\r\n",
      "To: /kaggle/working/CheXFound_Model/config.yaml\r\n",
      "100%|██████████████████████████████████████| 2.74k/2.74k [00:00<00:00, 12.2MB/s]\r\n",
      "Downloading...\r\n",
      "From (original): https://drive.google.com/uc?id=1i-cBIp0_jV4SRDrt4n1re5QVRUTAAUBQ\r\n",
      "From (redirected): https://drive.google.com/uc?id=1i-cBIp0_jV4SRDrt4n1re5QVRUTAAUBQ&confirm=t&uuid=fb095ffa-726c-4ac6-9227-28daf8a491b9\r\n",
      "To: /kaggle/working/CheXFound_Model/glori.pth\r\n",
      "100%|█████████████████████████████████████████| 940M/940M [00:04<00:00, 192MB/s]\r\n",
      "Downloading...\r\n",
      "From: https://drive.google.com/uc?id=1K9EJ9SKBkKx9eTGVOojdkkBfPRcPM6Ak\r\n",
      "To: /kaggle/working/CheXFound_Model/results_eval_linear.json\r\n",
      "100%|██████████████████████████████████████| 1.37k/1.37k [00:00<00:00, 7.80MB/s]\r\n",
      "Downloading...\r\n",
      "From (original): https://drive.google.com/uc?id=1qvbxNIVhTiUWwAnOYy83I8ZX7s__FaMQ\r\n",
      "From (redirected): https://drive.google.com/uc?id=1qvbxNIVhTiUWwAnOYy83I8ZX7s__FaMQ&confirm=t&uuid=b4c61353-7504-4b17-9bea-68222c228a42\r\n",
      "To: /kaggle/working/CheXFound_Model/teacher_checkpoint.pth\r\n",
      "100%|███████████████████████████████████████| 1.61G/1.61G [00:09<00:00, 167MB/s]\r\n",
      "Download completed\r\n"
     ]
    }
   ],
   "source": [
    "!pip install fvcore\n",
    "!pip install open_clip_torch\n",
    "# Cell 1: clone MaCo repo (change URL if you want your fork)\n",
    "!git clone https://github.com/RPIDIAL/CheXFound.git /kaggle/working/CheXFound\n",
    "!gdown --folder https://drive.google.com/drive/folders/1GX2BWbujuVABtVpSZ4PTBykGULzrw806 -O /kaggle/working/CheXFound_Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a73b756",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T10:06:47.267194Z",
     "iopub.status.busy": "2025-10-01T10:06:47.266480Z",
     "iopub.status.idle": "2025-10-01T10:06:47.271973Z",
     "shell.execute_reply": "2025-10-01T10:06:47.271299Z"
    },
    "papermill": {
     "duration": 0.101999,
     "end_time": "2025-10-01T10:06:47.273145",
     "exception": false,
     "start_time": "2025-10-01T10:06:47.171146",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell 3: add repo to PYTHONPATH in the current notebook (no restart)\n",
    "import sys\n",
    "repo_path = \"/kaggle/working/CheXFound\"\n",
    "if repo_path not in sys.path:\n",
    "    sys.path.insert(0, repo_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c74a83f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T10:06:47.333332Z",
     "iopub.status.busy": "2025-10-01T10:06:47.333093Z",
     "iopub.status.idle": "2025-10-01T10:07:20.540457Z",
     "shell.execute_reply": "2025-10-01T10:07:20.539691Z"
    },
    "papermill": {
     "duration": 33.239226,
     "end_time": "2025-10-01T10:07:20.541952",
     "exception": false,
     "start_time": "2025-10-01T10:06:47.302726",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/CheXFound/chexfound/layers/swiglu_ffn.py:51: UserWarning: xFormers is not available (SwiGLU)\n",
      "  warnings.warn(\"xFormers is not available (SwiGLU)\")\n",
      "/kaggle/working/CheXFound/chexfound/layers/attention.py:33: UserWarning: xFormers is not available (Attention)\n",
      "  warnings.warn(\"xFormers is not available (Attention)\")\n",
      "/kaggle/working/CheXFound/chexfound/layers/block.py:40: UserWarning: xFormers is not available (Block)\n",
      "  warnings.warn(\"xFormers is not available (Block)\")\n",
      "2025-10-01 10:07:05.441912: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1759313225.635546      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1759313225.693257      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('/kaggle/working/CheXFound')  # Change this path to the repository path\n",
    "import json\n",
    "import torch\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from chexfound.eval.setup import setup_and_build_model\n",
    "from chexfound.data.transforms import make_classification_eval_transform\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from chexfound.eval.utils import extract_hyperparameters_from_model\n",
    "from chexfound.eval.classification.utils import setup_glori\n",
    "from fvcore.common.checkpoint import Checkpointer\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import torchvision.io as io\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, KFold\n",
    "from torch.amp import autocast, GradScaler\n",
    "from torchvision.transforms import autoaugment, transforms\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "619e4257",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T10:07:20.600028Z",
     "iopub.status.busy": "2025-10-01T10:07:20.599500Z",
     "iopub.status.idle": "2025-10-01T10:07:20.607231Z",
     "shell.execute_reply": "2025-10-01T10:07:20.606716Z"
    },
    "papermill": {
     "duration": 0.037431,
     "end_time": "2025-10-01T10:07:20.608323",
     "exception": false,
     "start_time": "2025-10-01T10:07:20.570892",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89f07698",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T10:07:20.711922Z",
     "iopub.status.busy": "2025-10-01T10:07:20.711444Z",
     "iopub.status.idle": "2025-10-01T10:07:20.715985Z",
     "shell.execute_reply": "2025-10-01T10:07:20.715286Z"
    },
    "papermill": {
     "duration": 0.034765,
     "end_time": "2025-10-01T10:07:20.717109",
     "exception": false,
     "start_time": "2025-10-01T10:07:20.682344",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_class = 'Cardiomegaly'\n",
    "assert target_class in ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Pleural Effusion']\n",
    "\n",
    "base_dir = '/kaggle/working/CheXFound_Model/'  # Change to the directory storing checkpoints and configuration files\n",
    "\n",
    "config_file = base_dir + 'config.yaml'\n",
    "pretrained_weights = base_dir + 'teacher_checkpoint.pth'\n",
    "classifier_fpath = base_dir + 'glori.pth'\n",
    "classifier_json = base_dir + 'results_eval_linear.json'\n",
    "output_dir = base_dir + 'example'\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "308f0424",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T10:07:20.774685Z",
     "iopub.status.busy": "2025-10-01T10:07:20.774480Z",
     "iopub.status.idle": "2025-10-01T10:07:20.779147Z",
     "shell.execute_reply": "2025-10-01T10:07:20.778634Z"
    },
    "papermill": {
     "duration": 0.03493,
     "end_time": "2025-10-01T10:07:20.780247",
     "exception": false,
     "start_time": "2025-10-01T10:07:20.745317",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.set_defaults(\n",
    "    config_file=config_file,  # path to architecture configuration files\n",
    "    pretrained_weights=None,\n",
    "    output_dir=output_dir,\n",
    "    opts=[],\n",
    "    image_size=512,\n",
    "    patch_size=16,\n",
    "    n_register_tokens=4,\n",
    "    n_last_blocks=4,\n",
    "    return_class_token=True,\n",
    "    num_classes=40,\n",
    "    num_heads=8,\n",
    ")\n",
    "args, unknown = parser.parse_known_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc0780ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T10:07:20.837433Z",
     "iopub.status.busy": "2025-10-01T10:07:20.837222Z",
     "iopub.status.idle": "2025-10-01T10:07:27.681156Z",
     "shell.execute_reply": "2025-10-01T10:07:27.680339Z"
    },
    "papermill": {
     "duration": 6.874342,
     "end_time": "2025-10-01T10:07:27.682577",
     "exception": false,
     "start_time": "2025-10-01T10:07:20.808235",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[rank0]:[W1001 10:07:21.707765751 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I20251001 10:07:21 19 chexfound config.py:60] git:\n",
      "  sha: a4bac4956f3eeba4a8b2c15410c600536c7b0bce, status: has uncommitted changes, branch: main\n",
      "\n",
      "I20251001 10:07:21 19 chexfound config.py:61] config_file: /kaggle/working/CheXFound_Model/config.yaml\n",
      "image_size: 512\n",
      "n_last_blocks: 4\n",
      "n_register_tokens: 4\n",
      "num_classes: 40\n",
      "num_heads: 8\n",
      "opts: ['train.output_dir=/kaggle/working/CheXFound_Model/example']\n",
      "output_dir: /kaggle/working/CheXFound_Model/example\n",
      "patch_size: 16\n",
      "pretrained_weights: None\n",
      "return_class_token: True\n",
      "I20251001 10:07:21 19 chexfound config.py:26] sqrt scaling learning rate; base: 0.0002, new: 2.3385358667337133e-05\n",
      "I20251001 10:07:21 19 chexfound config.py:33] MODEL:\n",
      "  WEIGHTS: ''\n",
      "compute_precision:\n",
      "  grad_scaler: true\n",
      "  teacher:\n",
      "    backbone:\n",
      "      sharding_strategy: SHARD_GRAD_OP\n",
      "      mixed_precision:\n",
      "        param_dtype: fp16\n",
      "        reduce_dtype: fp16\n",
      "        buffer_dtype: fp32\n",
      "    dino_head:\n",
      "      sharding_strategy: SHARD_GRAD_OP\n",
      "      mixed_precision:\n",
      "        param_dtype: fp16\n",
      "        reduce_dtype: fp16\n",
      "        buffer_dtype: fp32\n",
      "    ibot_head:\n",
      "      sharding_strategy: SHARD_GRAD_OP\n",
      "      mixed_precision:\n",
      "        param_dtype: fp16\n",
      "        reduce_dtype: fp16\n",
      "        buffer_dtype: fp32\n",
      "  student:\n",
      "    backbone:\n",
      "      sharding_strategy: SHARD_GRAD_OP\n",
      "      mixed_precision:\n",
      "        param_dtype: fp16\n",
      "        reduce_dtype: fp16\n",
      "        buffer_dtype: fp32\n",
      "    dino_head:\n",
      "      sharding_strategy: SHARD_GRAD_OP\n",
      "      mixed_precision:\n",
      "        param_dtype: fp16\n",
      "        reduce_dtype: fp32\n",
      "        buffer_dtype: fp32\n",
      "    ibot_head:\n",
      "      sharding_strategy: SHARD_GRAD_OP\n",
      "      mixed_precision:\n",
      "        param_dtype: fp16\n",
      "        reduce_dtype: fp32\n",
      "        buffer_dtype: fp32\n",
      "dino:\n",
      "  loss_weight: 1.0\n",
      "  head_n_prototypes: 131072\n",
      "  head_bottleneck_dim: 384\n",
      "  head_nlayers: 3\n",
      "  head_hidden_dim: 2048\n",
      "  koleo_loss_weight: 0.1\n",
      "ibot:\n",
      "  loss_weight: 3.0\n",
      "  mask_sample_probability: 0.5\n",
      "  mask_ratio_min_max:\n",
      "  - 0.1\n",
      "  - 0.5\n",
      "  separate_head: true\n",
      "  head_n_prototypes: 131072\n",
      "  head_bottleneck_dim: 256\n",
      "  head_nlayers: 3\n",
      "  head_hidden_dim: 2048\n",
      "train:\n",
      "  batch_size_per_gpu: 14\n",
      "  dataset_path: CXRDatabase:split=TRAIN:root=/fast/yangz16/outputs/dinov2_split_512:extra=/fast/yangz16/outputs/dinov2_split_512/extra\n",
      "  output_dir: /kaggle/working/CheXFound_Model/example\n",
      "  saveckp_freq: 20\n",
      "  seed: 0\n",
      "  num_workers: 40\n",
      "  OFFICIAL_EPOCH_LENGTH: 2500\n",
      "  cache_dataset: true\n",
      "  centering: sinkhorn_knopp\n",
      "student:\n",
      "  arch: vit_large\n",
      "  patch_size: 16\n",
      "  drop_path_rate: 0.4\n",
      "  layerscale: 1.0e-05\n",
      "  drop_path_uniform: true\n",
      "  pretrained_weights: ''\n",
      "  ffn_layer: swiglufused\n",
      "  block_chunks: 0\n",
      "  qkv_bias: true\n",
      "  proj_bias: true\n",
      "  ffn_bias: true\n",
      "  num_register_tokens: 4\n",
      "  interpolate_antialias: false\n",
      "  interpolate_offset: 0.1\n",
      "teacher:\n",
      "  momentum_teacher: 0.994\n",
      "  final_momentum_teacher: 1\n",
      "  warmup_teacher_temp: 0.04\n",
      "  teacher_temp: 0.07\n",
      "  warmup_teacher_temp_epochs: 30\n",
      "optim:\n",
      "  epochs: 100\n",
      "  weight_decay: 0.04\n",
      "  weight_decay_end: 0.2\n",
      "  base_lr: 0.0002\n",
      "  lr: 2.3385358667337133e-05\n",
      "  warmup_epochs: 10\n",
      "  min_lr: 1.0e-06\n",
      "  clip_grad: 3.0\n",
      "  freeze_last_layer_epochs: 1\n",
      "  scaling_rule: sqrt_wrt_1024\n",
      "  patch_embed_lr_mult: 0.2\n",
      "  layerwise_decay: 1.0\n",
      "  adamw_beta1: 0.9\n",
      "  adamw_beta2: 0.999\n",
      "crops:\n",
      "  global_crops_scale:\n",
      "  - 0.32\n",
      "  - 1.0\n",
      "  local_crops_number: 8\n",
      "  local_crops_scale:\n",
      "  - 0.05\n",
      "  - 0.32\n",
      "  global_crops_size: 512\n",
      "  local_crops_size: 144\n",
      "evaluation:\n",
      "  eval_period_iterations: 5000\n",
      "\n",
      "I20251001 10:07:21 19 chexfound vision_transformer.py:125] using SwiGLU layer as FFN\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=[], unexpected_keys=['dino_head.mlp.0.weight', 'dino_head.mlp.0.bias', 'dino_head.mlp.2.weight', 'dino_head.mlp.2.bias', 'dino_head.mlp.4.weight', 'dino_head.mlp.4.bias', 'dino_head.last_layer.weight_g', 'dino_head.last_layer.weight_v', 'ibot_head.mlp.0.weight', 'ibot_head.mlp.0.bias', 'ibot_head.mlp.2.weight', 'ibot_head.mlp.2.bias', 'ibot_head.mlp.4.weight', 'ibot_head.mlp.4.bias', 'ibot_head.last_layer.weight_g', 'ibot_head.last_layer.weight_v'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set up foundation model\n",
    "base_model, autocast_dtype = setup_and_build_model(args)\n",
    "\n",
    "# load checkpoint for foundation model\n",
    "state_dict = torch.load(pretrained_weights)['teacher']\n",
    "new_state_dict = {}\n",
    "for k, v in state_dict.items():\n",
    "    if k.startswith('backbone'):\n",
    "        ls = k.split('.')\n",
    "        if 'blocks' in k:\n",
    "            new_k = '.'.join([ls[1], *ls[3:]])\n",
    "        else:\n",
    "            new_k = '.'.join(ls[1:])\n",
    "    else:\n",
    "        new_k = k\n",
    "    new_state_dict.update({new_k: v})\n",
    "\n",
    "base_model.load_state_dict(new_state_dict, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2278b98f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T10:07:27.741156Z",
     "iopub.status.busy": "2025-10-01T10:07:27.740881Z",
     "iopub.status.idle": "2025-10-01T10:07:29.085746Z",
     "shell.execute_reply": "2025-10-01T10:07:29.085059Z"
    },
    "papermill": {
     "duration": 1.374776,
     "end_time": "2025-10-01T10:07:29.086763",
     "exception": false,
     "start_time": "2025-10-01T10:07:27.711987",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I20251001 10:07:28 19 fvcore.common.checkpoint checkpoint.py:150] [Checkpointer] Loading from /kaggle/working/CheXFound_Model/glori.pth ...\n",
      "W20251001 10:07:29 19 fvcore.common.checkpoint checkpoint.py:352] The checkpoint state_dict contains keys that are not used by the model:\n",
      "  classifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000100000.decoder.{duplicate_pooling, duplicate_pooling_bias}\n",
      "  classifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000100000.decoder.layers.0.norm1.{bias, weight}\n",
      "  classifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000100000.decoder.layers.0.multihead_attn.{in_proj_bias, in_proj_weight}\n",
      "  classifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000100000.decoder.layers.0.multihead_attn.out_proj.{bias, weight}\n",
      "  classifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000100000.decoder.layers.0.linear1.{bias, weight}\n",
      "  classifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000100000.decoder.layers.0.linear2.{bias, weight}\n",
      "  classifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000100000.decoder.layers.0.norm2.{bias, weight}\n",
      "  classifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000100000.decoder.layers.0.norm3.{bias, weight}\n",
      "  classifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000100000.decoder.embed_standart.{bias, weight}\n",
      "  classifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000100000.decoder.query_embed.weight\n",
      "  classifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000200000.decoder.{duplicate_pooling, duplicate_pooling_bias}\n",
      "  classifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000200000.decoder.layers.0.norm1.{bias, weight}\n",
      "  classifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000200000.decoder.layers.0.multihead_attn.{in_proj_bias, in_proj_weight}\n",
      "  classifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000200000.decoder.layers.0.multihead_attn.out_proj.{bias, weight}\n",
      "  classifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000200000.decoder.layers.0.linear1.{bias, weight}\n",
      "  classifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000200000.decoder.layers.0.linear2.{bias, weight}\n",
      "  classifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000200000.decoder.layers.0.norm2.{bias, weight}\n",
      "  classifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000200000.decoder.layers.0.norm3.{bias, weight}\n",
      "  classifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000200000.decoder.embed_standart.{bias, weight}\n",
      "  classifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000200000.decoder.query_embed.weight\n",
      "  classifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000500000.decoder.{duplicate_pooling, duplicate_pooling_bias}\n",
      "  classifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000500000.decoder.layers.0.norm1.{bias, weight}\n",
      "  classifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000500000.decoder.layers.0.multihead_attn.{in_proj_bias, in_proj_weight}\n",
      "  classifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000500000.decoder.layers.0.multihead_attn.out_proj.{bias, weight}\n",
      "  classifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000500000.decoder.layers.0.linear1.{bias, weight}\n",
      "  classifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000500000.decoder.layers.0.linear2.{bias, weight}\n",
      "  classifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000500000.decoder.layers.0.norm2.{bias, weight}\n",
      "  classifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000500000.decoder.layers.0.norm3.{bias, weight}\n",
      "  classifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000500000.decoder.embed_standart.{bias, weight}\n",
      "  classifiers_dict.linear:blocks=4:avgpool=False:lr=0_0000500000.decoder.query_embed.weight\n",
      "  classifiers_dict.linear:blocks=4:avgpool=False:lr=0_0001000000.decoder.{duplicate_pooling, duplicate_pooling_bias}\n",
      "  classifiers_dict.linear:blocks=4:avgpool=False:lr=0_0001000000.decoder.layers.0.norm1.{bias, weight}\n",
      "  classifiers_dict.linear:blocks=4:avgpool=False:lr=0_0001000000.decoder.layers.0.multihead_attn.{in_proj_bias, in_proj_weight}\n",
      "  classifiers_dict.linear:blocks=4:avgpool=False:lr=0_0001000000.decoder.layers.0.multihead_attn.out_proj.{bias, weight}\n",
      "  classifiers_dict.linear:blocks=4:avgpool=False:lr=0_0001000000.decoder.layers.0.linear1.{bias, weight}\n",
      "  classifiers_dict.linear:blocks=4:avgpool=False:lr=0_0001000000.decoder.layers.0.linear2.{bias, weight}\n",
      "  classifiers_dict.linear:blocks=4:avgpool=False:lr=0_0001000000.decoder.layers.0.norm2.{bias, weight}\n",
      "  classifiers_dict.linear:blocks=4:avgpool=False:lr=0_0001000000.decoder.layers.0.norm3.{bias, weight}\n",
      "  classifiers_dict.linear:blocks=4:avgpool=False:lr=0_0001000000.decoder.embed_standart.{bias, weight}\n",
      "  classifiers_dict.linear:blocks=4:avgpool=False:lr=0_0001000000.decoder.query_embed.weight\n",
      "  classifiers_dict.linear:blocks=4:avgpool=False:lr=0_0002000000.decoder.{duplicate_pooling, duplicate_pooling_bias}\n",
      "  classifiers_dict.linear:blocks=4:avgpool=False:lr=0_0002000000.decoder.layers.0.norm1.{bias, weight}\n",
      "  classifiers_dict.linear:blocks=4:avgpool=False:lr=0_0002000000.decoder.layers.0.multihead_attn.{in_proj_bias, in_proj_weight}\n",
      "  classifiers_dict.linear:blocks=4:avgpool=False:lr=0_0002000000.decoder.layers.0.multihead_attn.out_proj.{bias, weight}\n",
      "  classifiers_dict.linear:blocks=4:avgpool=False:lr=0_0002000000.decoder.layers.0.linear1.{bias, weight}\n",
      "  classifiers_dict.linear:blocks=4:avgpool=False:lr=0_0002000000.decoder.layers.0.linear2.{bias, weight}\n",
      "  classifiers_dict.linear:blocks=4:avgpool=False:lr=0_0002000000.decoder.layers.0.norm2.{bias, weight}\n",
      "  classifiers_dict.linear:blocks=4:avgpool=False:lr=0_0002000000.decoder.layers.0.norm3.{bias, weight}\n",
      "  classifiers_dict.linear:blocks=4:avgpool=False:lr=0_0002000000.decoder.embed_standart.{bias, weight}\n",
      "  classifiers_dict.linear:blocks=4:avgpool=False:lr=0_0002000000.decoder.query_embed.weight\n",
      "  classifiers_dict.linear:blocks=4:avgpool=False:lr=0_0010000000.decoder.{duplicate_pooling, duplicate_pooling_bias}\n",
      "  classifiers_dict.linear:blocks=4:avgpool=False:lr=0_0010000000.decoder.layers.0.norm1.{bias, weight}\n",
      "  classifiers_dict.linear:blocks=4:avgpool=False:lr=0_0010000000.decoder.layers.0.multihead_attn.{in_proj_bias, in_proj_weight}\n",
      "  classifiers_dict.linear:blocks=4:avgpool=False:lr=0_0010000000.decoder.layers.0.multihead_attn.out_proj.{bias, weight}\n",
      "  classifiers_dict.linear:blocks=4:avgpool=False:lr=0_0010000000.decoder.layers.0.linear1.{bias, weight}\n",
      "  classifiers_dict.linear:blocks=4:avgpool=False:lr=0_0010000000.decoder.layers.0.linear2.{bias, weight}\n",
      "  classifiers_dict.linear:blocks=4:avgpool=False:lr=0_0010000000.decoder.layers.0.norm2.{bias, weight}\n",
      "  classifiers_dict.linear:blocks=4:avgpool=False:lr=0_0010000000.decoder.layers.0.norm3.{bias, weight}\n",
      "  classifiers_dict.linear:blocks=4:avgpool=False:lr=0_0010000000.decoder.embed_standart.{bias, weight}\n",
      "  classifiers_dict.linear:blocks=4:avgpool=False:lr=0_0010000000.decoder.query_embed.weight\n",
      "  classifiers_dict.linear:blocks=4:avgpool=False:lr=0_0020000000.decoder.{duplicate_pooling, duplicate_pooling_bias}\n",
      "  classifiers_dict.linear:blocks=4:avgpool=False:lr=0_0020000000.decoder.layers.0.norm1.{bias, weight}\n",
      "  classifiers_dict.linear:blocks=4:avgpool=False:lr=0_0020000000.decoder.layers.0.multihead_attn.{in_proj_bias, in_proj_weight}\n",
      "  classifiers_dict.linear:blocks=4:avgpool=False:lr=0_0020000000.decoder.layers.0.multihead_attn.out_proj.{bias, weight}\n",
      "  classifiers_dict.linear:blocks=4:avgpool=False:lr=0_0020000000.decoder.layers.0.linear1.{bias, weight}\n",
      "  classifiers_dict.linear:blocks=4:avgpool=False:lr=0_0020000000.decoder.layers.0.linear2.{bias, weight}\n",
      "  classifiers_dict.linear:blocks=4:avgpool=False:lr=0_0020000000.decoder.layers.0.norm2.{bias, weight}\n",
      "  classifiers_dict.linear:blocks=4:avgpool=False:lr=0_0020000000.decoder.layers.0.norm3.{bias, weight}\n",
      "  classifiers_dict.linear:blocks=4:avgpool=False:lr=0_0020000000.decoder.embed_standart.{bias, weight}\n",
      "  classifiers_dict.linear:blocks=4:avgpool=False:lr=0_0020000000.decoder.query_embed.weight\n",
      "  classifiers_dict.linear:blocks=4:avgpool=False:lr=0_0050000000.decoder.{duplicate_pooling, duplicate_pooling_bias}\n",
      "  classifiers_dict.linear:blocks=4:avgpool=False:lr=0_0050000000.decoder.layers.0.norm1.{bias, weight}\n",
      "  classifiers_dict.linear:blocks=4:avgpool=False:lr=0_0050000000.decoder.layers.0.multihead_attn.{in_proj_bias, in_proj_weight}\n",
      "  classifiers_dict.linear:blocks=4:avgpool=False:lr=0_0050000000.decoder.layers.0.multihead_attn.out_proj.{bias, weight}\n",
      "  classifiers_dict.linear:blocks=4:avgpool=False:lr=0_0050000000.decoder.layers.0.linear1.{bias, weight}\n",
      "  classifiers_dict.linear:blocks=4:avgpool=False:lr=0_0050000000.decoder.layers.0.linear2.{bias, weight}\n",
      "  classifiers_dict.linear:blocks=4:avgpool=False:lr=0_0050000000.decoder.layers.0.norm2.{bias, weight}\n",
      "  classifiers_dict.linear:blocks=4:avgpool=False:lr=0_0050000000.decoder.layers.0.norm3.{bias, weight}\n",
      "  classifiers_dict.linear:blocks=4:avgpool=False:lr=0_0050000000.decoder.embed_standart.{bias, weight}\n",
      "  classifiers_dict.linear:blocks=4:avgpool=False:lr=0_0050000000.decoder.query_embed.weight\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# set up glori head\n",
    "log_json = classifier_json\n",
    "with open(log_json, 'r') as f:\n",
    "    content = f.read().split('\\n')[-3]\n",
    "    data = json.loads(content)\n",
    "best_classifier_str = data['best_classifier']['name']\n",
    "hyperparameters = extract_hyperparameters_from_model(best_classifier_str)\n",
    "learning_rate, avgpool, block = hyperparameters[\"lr\"], hyperparameters[\"avgpool\"], hyperparameters[\"blocks\"]\n",
    "\n",
    "sample_input = torch.randn(1, 3, 512, 512).cuda()\n",
    "with torch.no_grad():\n",
    "    sample_output = base_model.get_intermediate_layers(sample_input, n=args.n_last_blocks, return_class_token=True)\n",
    "\n",
    "glori, _ = setup_glori(\n",
    "    sample_output=sample_output,\n",
    "    n_last_blocks_list=block,\n",
    "    learning_rates=learning_rate,\n",
    "    avgpools=avgpool,\n",
    "    num_classes=args.num_classes,\n",
    "    multiview=False,\n",
    "    decoder_dim=768,\n",
    "    cat_cls=False,\n",
    ")\n",
    "\n",
    "# load checkpoint for glori classifier\n",
    "checkpointer = Checkpointer(glori)\n",
    "checkpointer.load(classifier_fpath)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f452580c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T10:07:29.145767Z",
     "iopub.status.busy": "2025-10-01T10:07:29.145546Z",
     "iopub.status.idle": "2025-10-01T10:07:29.149888Z",
     "shell.execute_reply": "2025-10-01T10:07:29.149395Z"
    },
    "papermill": {
     "duration": 0.034296,
     "end_time": "2025-10-01T10:07:29.150936",
     "exception": false,
     "start_time": "2025-10-01T10:07:29.116640",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistributedDataParallel(\n",
       "  (module): AllClassifiers(\n",
       "    (classifiers_dict): ModuleDict(\n",
       "      (linear:blocks=4:avgpool=False:lr=0_0005000000): GLoRI(\n",
       "        (decoder): TransformerDecoder(\n",
       "          (layers): ModuleList(\n",
       "            (0): TransformerDecoderLayerOptimal(\n",
       "              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (dropout1): Dropout(p=0.1, inplace=False)\n",
       "              (dropout2): Dropout(p=0.1, inplace=False)\n",
       "              (dropout3): Dropout(p=0.1, inplace=False)\n",
       "              (multihead_attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (linear1): Linear(in_features=768, out_features=2048, bias=True)\n",
       "              (linear2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (embed_standart): Linear(in_features=4096, out_features=768, bias=True)\n",
       "          (query_embed): Embedding(40, 768)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34776329",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T10:07:29.211355Z",
     "iopub.status.busy": "2025-10-01T10:07:29.211144Z",
     "iopub.status.idle": "2025-10-01T10:07:29.223735Z",
     "shell.execute_reply": "2025-10-01T10:07:29.223145Z"
    },
    "papermill": {
     "duration": 0.044672,
     "end_time": "2025-10-01T10:07:29.224745",
     "exception": false,
     "start_time": "2025-10-01T10:07:29.180073",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder found: <class 'chexfound.eval.classification.glori.TransformerDecoder'>\n",
      "Decoder.num_classes (before): 40\n",
      "Set decoder.num_classes -> 14\n",
      "Old duplicate_pooling_bias shape: (40,)\n",
      "Replaced duplicate_pooling_bias with shape: torch.Size([14])\n",
      "Replaced parameter/buffer names: []\n",
      "Moved glori to device.\n"
     ]
    }
   ],
   "source": [
    "# ---------- Fix decoder internals (resize biases / num_classes) ----------\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "TARGET_CLASSES = 14\n",
    "ORIG_CLASSES = 40\n",
    "\n",
    "# get classifier same way as before\n",
    "glori_wrapped = glori\n",
    "glori_module = getattr(glori_wrapped, \"module\", glori_wrapped)\n",
    "classifier_key = next(iter(glori_module.classifiers_dict.keys()))\n",
    "classifier = glori_module.classifiers_dict[classifier_key]\n",
    "decoder = getattr(classifier, \"decoder\", None)\n",
    "if decoder is None:\n",
    "    raise RuntimeError(\"Decoder not found in classifier; cannot resize num_classes. Print classifier to inspect.\")\n",
    "\n",
    "print(\"Decoder found:\", type(decoder))\n",
    "print(\"Decoder.num_classes (before):\", getattr(decoder, \"num_classes\", None))\n",
    "\n",
    "# 1) set decoder.num_classes\n",
    "decoder.num_classes = TARGET_CLASSES\n",
    "print(\"Set decoder.num_classes ->\", decoder.num_classes)\n",
    "\n",
    "# 2) replace duplicate_pooling_bias if exists (common in this implementation)\n",
    "if hasattr(decoder, \"duplicate_pooling_bias\"):\n",
    "    old = decoder.duplicate_pooling_bias\n",
    "    print(\"Old duplicate_pooling_bias shape:\", tuple(old.shape) if isinstance(old, torch.Tensor) else type(old))\n",
    "    # create new bias param\n",
    "    new_bias = nn.Parameter(torch.zeros(TARGET_CLASSES, dtype=torch.float32, device=device))\n",
    "    # init small (optional)\n",
    "    nn.init.constant_(new_bias, 0.0)\n",
    "    # assign (if module originally on CPU, move)\n",
    "    decoder.duplicate_pooling_bias = new_bias\n",
    "    print(\"Replaced duplicate_pooling_bias with shape:\", decoder.duplicate_pooling_bias.shape)\n",
    "else:\n",
    "    print(\"No attribute duplicate_pooling_bias found on decoder — fine.\")\n",
    "\n",
    "# 3) scan decoder for any 1D parameters/buffers whose length equals ORIG_CLASSES and replace them (safe heuristic)\n",
    "replaced = []\n",
    "for name, param in list(decoder.named_parameters()):\n",
    "    if param.dim() == 1 and param.shape[0] == ORIG_CLASSES:\n",
    "        print(f\"Resizing param: {name} shape {param.shape} -> {TARGET_CLASSES}\")\n",
    "        parent = decoder\n",
    "        parts = name.split('.')\n",
    "        for p in parts[:-1]:\n",
    "            parent = getattr(parent, p)\n",
    "        attr = parts[-1]\n",
    "        new_p = nn.Parameter(torch.zeros(TARGET_CLASSES, dtype=param.dtype, device=device))\n",
    "        setattr(parent, attr, new_p)\n",
    "        replaced.append(name)\n",
    "\n",
    "# also check buffers (non-parameter tensors)\n",
    "for name, buf in list(decoder.named_buffers()):\n",
    "    if buf is None:\n",
    "        continue\n",
    "    if buf.ndim == 1 and buf.shape[0] == ORIG_CLASSES:\n",
    "        print(f\"Resizing buffer: {name} shape {buf.shape} -> {TARGET_CLASSES}\")\n",
    "        parent = decoder\n",
    "        parts = name.split('.')\n",
    "        for p in parts[:-1]:\n",
    "            parent = getattr(parent, p)\n",
    "        attr = parts[-1]\n",
    "        # assign as buffer\n",
    "        decoder.register_buffer(attr, torch.zeros(TARGET_CLASSES, dtype=buf.dtype, device=device))\n",
    "        replaced.append(\"buffer:\"+name)\n",
    "\n",
    "print(\"Replaced parameter/buffer names:\", replaced)\n",
    "\n",
    "# 4) move whole glori to device again and do a quick forward test\n",
    "glori_wrapped.to(device)\n",
    "print(\"Moved glori to device.\")\n",
    "\n",
    "# Ensure backbone frozen if desired\n",
    "for p in base_model.parameters():\n",
    "    p.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eacd2244",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T10:07:29.283718Z",
     "iopub.status.busy": "2025-10-01T10:07:29.283521Z",
     "iopub.status.idle": "2025-10-01T10:07:29.287736Z",
     "shell.execute_reply": "2025-10-01T10:07:29.287231Z"
    },
    "papermill": {
     "duration": 0.03485,
     "end_time": "2025-10-01T10:07:29.288782",
     "exception": false,
     "start_time": "2025-10-01T10:07:29.253932",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 6) Wrap backbone + new glori into a training model\n",
    "class CheXFoundWithGLoRIHead(nn.Module):\n",
    "    def __init__(self, backbone, glori_module, args):\n",
    "        super().__init__()\n",
    "        self.backbone = backbone\n",
    "        self.glori = glori_module\n",
    "        self.args = args\n",
    "    def forward(self, x):\n",
    "        # get intermediate features and pass to glori\n",
    "        feats = self.backbone.get_intermediate_layers(x, n=self.args.n_last_blocks, return_class_token=self.args.return_class_token)\n",
    "        logits_dict = self.glori([feats], return_attention=False)\n",
    "        key = list(logits_dict.keys())[0]\n",
    "        return logits_dict[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e98826f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T10:07:29.347849Z",
     "iopub.status.busy": "2025-10-01T10:07:29.347644Z",
     "iopub.status.idle": "2025-10-01T10:07:29.838882Z",
     "shell.execute_reply": "2025-10-01T10:07:29.838134Z"
    },
    "papermill": {
     "duration": 0.521983,
     "end_time": "2025-10-01T10:07:29.840067",
     "exception": false,
     "start_time": "2025-10-01T10:07:29.318084",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W20251001 10:07:29 19 py.warnings warnings.py:110] /tmp/ipykernel_19/1834097517.py:59: UserWarning: Argument(s) 'max_holes, max_height, max_width' are not valid for transform CoarseDropout\n",
      "  A.CoarseDropout(max_holes=1, max_height=20, max_width=20, p=0.2),\n",
      "\n",
      "W20251001 10:07:29 19 py.warnings warnings.py:110] /usr/local/lib/python3.11/dist-packages/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
      "  original_init(self, **validated_kwargs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "cv2.setNumThreads(0)\n",
    "\n",
    "class ChestXrayDataset(Dataset):\n",
    "    def __init__(self, df, img_dir, transform=None):\n",
    "        self.df = df\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.label_cols = [\n",
    "            \"Atelectasis\",\"Cardiomegaly\",\"Consolidation\",\"Edema\",\n",
    "            \"Enlarged Cardiomediastinum\",\"Fracture\",\"Lung Lesion\",\n",
    "            \"Lung Opacity\",\"No Finding\",\"Pleural Effusion\",\"Pleural Other\",\n",
    "            \"Pneumonia\",\"Pneumothorax\",\"Support Devices\",\n",
    "        ]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = os.path.join(self.img_dir, row[\"Image_name\"])\n",
    "\n",
    "        # Fast read with OpenCV. It may return None if file missing -> handle.\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)\n",
    "        if img is None:\n",
    "            raise FileNotFoundError(f\"Image not found: {img_path}\")\n",
    "\n",
    "        # If grayscale (H, W), convert to 3-channel\n",
    "        if img.ndim == 2:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "        elif img.shape[2] == 4:\n",
    "            # if RGBA, convert to RGB\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGRA2BGR)\n",
    "\n",
    "        # OpenCV loads BGR -> convert to RGB\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=img)\n",
    "            img = augmented[\"image\"]\n",
    "\n",
    "        labels = torch.tensor(row[self.label_cols].values.astype(\"float32\"))\n",
    "        return img, labels\n",
    "\n",
    "# choose img_size once\n",
    "img_size = 512\n",
    "size_tuple = (img_size, img_size)   # IMPORTANT: albumentations expects a tuple\n",
    "\n",
    "train_tfms = A.Compose([\n",
    "    A.RandomResizedCrop(size=size_tuple, scale=(0.85, 1.0), ratio=(0.9, 1.1)),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.Rotate(limit=12, p=0.4),\n",
    "    A.CLAHE(p=0.3),\n",
    "    A.RandomBrightnessContrast(p=0.3),\n",
    "    A.CoarseDropout(max_holes=1, max_height=20, max_width=20, p=0.2),\n",
    "    A.ShiftScaleRotate(shift_limit=0.03, scale_limit=0.05, rotate_limit=0, p=0.25),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "val_tfms = A.Compose([\n",
    "    A.Resize(height=img_size, width=img_size),   # pass height & width\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42bf38af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T10:07:29.899617Z",
     "iopub.status.busy": "2025-10-01T10:07:29.898900Z",
     "iopub.status.idle": "2025-10-01T10:07:29.908210Z",
     "shell.execute_reply": "2025-10-01T10:07:29.907664Z"
    },
    "papermill": {
     "duration": 0.039837,
     "end_time": "2025-10-01T10:07:29.909327",
     "exception": false,
     "start_time": "2025-10-01T10:07:29.869490",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.amp import autocast, GradScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "scaler = GradScaler(device=\"cuda\")\n",
    "\n",
    "#EMA\n",
    "# -----------------------------\n",
    "# Train One Epoch (with AMP)\n",
    "# -----------------------------\n",
    "def train_one_epoch(model, loader, optimizer, criterion, ema=None, grad_clip=1.0):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    progress_bar = tqdm(loader, desc=\"[Train]\")\n",
    "    for imgs, labels in progress_bar:\n",
    "        imgs, labels = imgs.to(DEVICE), labels.to(DEVICE).float()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with autocast(device_type=\"cuda\" ):  # mixed precision forward\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        # scaler.unscale_(optimizer)\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        if ema is not None:\n",
    "            ema.update(model)\n",
    "    #     if ema is not None:\n",
    "    #         # support DataParallel-wrapped EMA as well as normal EMA\n",
    "    #         ema_core = getattr(ema, \"module\", ema)\n",
    "    #         ema_core.update(model)\n",
    "\n",
    "        running_loss += loss.item() * imgs.size(0)\n",
    "    return running_loss / len(loader.dataset)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Validation (macro + per-label AUROC)\n",
    "# -----------------------------\n",
    "def validate(model, loader, criterion):\n",
    "    \n",
    "    model = nn.DataParallel(model)\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    all_labels, all_outputs = [], []\n",
    "\n",
    "    progress_bar = tqdm(loader, desc=\"[Val]\")\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in progress_bar:\n",
    "            imgs, labels = imgs.to(DEVICE), labels.to(DEVICE).float()\n",
    "            with autocast(device_type=\"cuda\" ):\n",
    "                outputs = model(imgs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * imgs.size(0)\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "            all_outputs.append(outputs.sigmoid().cpu().numpy())\n",
    "\n",
    "    all_labels = np.vstack(all_labels)\n",
    "    all_outputs = np.vstack(all_outputs)\n",
    "\n",
    "    per_label_auc = {}\n",
    "    for i, label in enumerate(loader.dataset.label_cols):\n",
    "        try:\n",
    "            per_label_auc[label] = roc_auc_score(all_labels[:, i], all_outputs[:, i])\n",
    "        except ValueError:\n",
    "            per_label_auc[label] = np.nan\n",
    "\n",
    "    try:\n",
    "        #macro_auc = roc_auc_score(all_labels, all_outputs, average=\"macro\", multi_class=\"ovo\")\n",
    "        macro_auc = roc_auc_score(all_labels, all_outputs, average=\"macro\")\n",
    "    except ValueError:\n",
    "        macro_auc = np.nan\n",
    "\n",
    "    return running_loss / len(loader.dataset), macro_auc, per_label_auc\n",
    "\n",
    "\n",
    "# Learning rate scheduler\n",
    "def get_scheduler(optimizer, num_training_steps):\n",
    "    scheduler = get_cosine_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=int(num_training_steps * 0.1),\n",
    "        num_training_steps=num_training_steps,\n",
    "    )\n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "88d26b64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T10:07:29.968423Z",
     "iopub.status.busy": "2025-10-01T10:07:29.968211Z",
     "iopub.status.idle": "2025-10-01T10:07:29.975654Z",
     "shell.execute_reply": "2025-10-01T10:07:29.975136Z"
    },
    "papermill": {
     "duration": 0.038431,
     "end_time": "2025-10-01T10:07:29.976763",
     "exception": false,
     "start_time": "2025-10-01T10:07:29.938332",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.25, gamma=2.0, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        BCE_loss = nn.functional.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-BCE_loss)  # pt = p if target=1, 1-p otherwise\n",
    "        focal_loss = self.alpha * (1-pt)**self.gamma * BCE_loss\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return focal_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return focal_loss.sum()\n",
    "        else:\n",
    "            return focal_loss\n",
    "\n",
    "class WeightedFocalBCELoss(nn.Module):\n",
    "    def __init__(self, alpha=0.25, gamma=2.0, pos_weights=None):\n",
    "        super().__init__()\n",
    "        self.focal = FocalLoss(alpha, gamma)\n",
    "        self.bce = nn.BCEWithLogitsLoss(pos_weight=pos_weights)\n",
    "        self.alpha = 0.7  # Weight between focal and BCE\n",
    "        \n",
    "    def forward(self, inputs, targets):\n",
    "        focal_loss = self.focal(inputs, targets)\n",
    "        bce_loss = self.bce(inputs, targets)\n",
    "        return self.alpha * focal_loss + (1 - self.alpha) * bce_loss\n",
    "\n",
    "# Calculate better class weights\n",
    "def calculate_effective_weights(df, label_cols, beta=0.999):\n",
    "    \"\"\"Calculate more robust class weights using effective number of samples\"\"\"\n",
    "    n = len(df)\n",
    "    weights = []\n",
    "    for col in label_cols:\n",
    "        pos_count = df[col].sum()\n",
    "        neg_count = n - pos_count\n",
    "        \n",
    "        # Effective number of samples (from Class-Balanced Loss paper)\n",
    "        eff_pos = (1 - beta**pos_count) / (1 - beta) if pos_count > 0 else 0\n",
    "        eff_neg = (1 - beta**neg_count) / (1 - beta) if neg_count > 0 else 0\n",
    "        \n",
    "        weight = eff_neg / (eff_pos + 1e-8)  # Avoid division by zero\n",
    "        weights.append(min(weight, 10.0))  # Cap extreme weights\n",
    "    \n",
    "    return torch.tensor(weights).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c781444",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T10:07:30.035795Z",
     "iopub.status.busy": "2025-10-01T10:07:30.035592Z",
     "iopub.status.idle": "2025-10-01T10:07:30.040375Z",
     "shell.execute_reply": "2025-10-01T10:07:30.039842Z"
    },
    "papermill": {
     "duration": 0.035907,
     "end_time": "2025-10-01T10:07:30.041423",
     "exception": false,
     "start_time": "2025-10-01T10:07:30.005516",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ModelEMA:\n",
    "    def __init__(self, model, decay=0.9997, device=None):\n",
    "        # copy *unwrapped* module (so EMA keys match saved/loaded model keys)\n",
    "        self.decay = decay\n",
    "        self.device = device\n",
    "        self.ema = copy.deepcopy(get_model(model)).eval()\n",
    "        if device is not None:\n",
    "            self.ema.to(device)\n",
    "        for p in self.ema.parameters():\n",
    "            p.requires_grad_(False)\n",
    "\n",
    "    def update(self, model):\n",
    "        src_state = get_model(model).state_dict()\n",
    "        with torch.no_grad():\n",
    "            for k, v in self.ema.state_dict().items():\n",
    "                model_v = src_state[k].detach().to(v.device)\n",
    "                v.copy_(v * self.decay + (1.0 - self.decay) * model_v)\n",
    "\n",
    "    def state_dict(self):\n",
    "        return self.ema.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16b37420",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T10:07:30.099666Z",
     "iopub.status.busy": "2025-10-01T10:07:30.099460Z",
     "iopub.status.idle": "2025-10-01T10:07:30.102452Z",
     "shell.execute_reply": "2025-10-01T10:07:30.101935Z"
    },
    "papermill": {
     "duration": 0.033227,
     "end_time": "2025-10-01T10:07:30.103461",
     "exception": false,
     "start_time": "2025-10-01T10:07:30.070234",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_model(module):\n",
    "    \"\"\"Return the underlying model (unwrap DataParallel / DDP).\"\"\"\n",
    "    return module.module if hasattr(module, \"module\") else module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a51b95bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T10:07:30.161681Z",
     "iopub.status.busy": "2025-10-01T10:07:30.161476Z",
     "iopub.status.idle": "2025-10-01T18:47:40.358372Z",
     "shell.execute_reply": "2025-10-01T18:47:40.357279Z"
    },
    "papermill": {
     "duration": 31210.22785,
     "end_time": "2025-10-01T18:47:40.359782",
     "exception": false,
     "start_time": "2025-10-01T10:07:30.131932",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing model on device: cuda GPUs: 2\n",
      "Unwrapping glori from DDP wrapper -> using glori.module\n",
      "Wrapping train_model with nn.DataParallel for multi-GPU\n",
      "Trainable glori params count: 8723470\n",
      "W20251001 10:07:46 19 py.warnings warnings.py:110] /usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "\n",
      "Epoch 4/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train]: 100%|██████████| 1678/1678 [2:53:08<00:00,  6.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4] TrainLoss=0.0966 \n",
      "✅ Saved new best model  -> best_model_f4.pth\n",
      "Epoch 5/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train]: 100%|██████████| 1678/1678 [2:53:01<00:00,  6.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5] TrainLoss=0.0954 \n",
      "✅ Saved new best model  -> best_model_f5.pth\n",
      "Epoch 6/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train]: 100%|██████████| 1678/1678 [2:53:32<00:00,  6.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6] TrainLoss=0.0944 \n",
      "✅ Saved new best model  -> best_model_f6.pth\n"
     ]
    }
   ],
   "source": [
    "EPOCHS=6\n",
    "\n",
    "# -----------------------------\n",
    "# Run Training\n",
    "# -----------------------------\n",
    "\n",
    "# # Prepare for cross-validation\n",
    "# kf = KFold(n_splits=5, shuffle=True, random_state=32)\n",
    "fold_results = []\n",
    "\n",
    "df_all = pd.read_csv('/kaggle/input/grand-xray-slam-division-a/train1.csv')\n",
    "df_all = df_all[~df_all['Image_name'].isin([\n",
    "    '00043046_001_001.jpg',\n",
    "    '00052495_001_001.jpg',\n",
    "    '00056890_001_001.jpg'\n",
    "])]\n",
    "\n",
    "label_cols = [\n",
    "            \"Atelectasis\",\n",
    "            \"Cardiomegaly\",\n",
    "            \"Consolidation\",\n",
    "            \"Edema\",\n",
    "            \"Enlarged Cardiomediastinum\",\n",
    "            \"Fracture\",\n",
    "            \"Lung Lesion\",\n",
    "            \"Lung Opacity\",\n",
    "            \"No Finding\",\n",
    "            \"Pleural Effusion\",\n",
    "            \"Pleural Other\",\n",
    "            \"Pneumonia\",\n",
    "            \"Pneumothorax\",\n",
    "            \"Support Devices\",\n",
    "        ]\n",
    "\n",
    "    \n",
    "\n",
    "best_auc = -1.0   # track best AUC\n",
    "best_loss = float(\"inf\")\n",
    "# Create datasets\n",
    "train_df = df_all.copy()\n",
    "#val_df = df_all.iloc[val_idx].copy()\n",
    "# -----------------------------\n",
    "# Model: EVAX base\n",
    "# -----------------------------\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# #model = CheXFound_Model(model)\n",
    "# model = train_model\n",
    "\n",
    "# -----------------------------\n",
    "# Loss & Optimizer\n",
    "# -----------------------------\n",
    "\n",
    "#criterion = FocalLoss(alpha=0.25, gamma=2.0)\n",
    "pos_weights = calculate_effective_weights(train_df, label_cols, beta=0.9999)\n",
    "criterion = WeightedFocalBCELoss(alpha=0.25, gamma=2.0, pos_weights=pos_weights.to(DEVICE))\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# SAFE unwrap & prepare model for multi-GPU\n",
    "# -------------------------\n",
    "print(\"Preparing model on device:\", DEVICE, \"GPUs:\", torch.cuda.device_count())\n",
    "\n",
    "# 1) If glori is a DDP wrapper, unwrap to get the real module\n",
    "glori_wrapped = glori  # original object you loaded\n",
    "if hasattr(glori_wrapped, \"module\"):\n",
    "    print(\"Unwrapping glori from DDP wrapper -> using glori.module\")\n",
    "    glori_clean = glori_wrapped.module\n",
    "else:\n",
    "    glori_clean = glori_wrapped\n",
    "\n",
    "# move glori_clean to CPU to avoid device mismatch while assembling\n",
    "glori_clean = glori_clean.cpu()\n",
    "\n",
    "# 2) Rebuild train_model with the unwrapped glori (fresh object)\n",
    "train_model = CheXFoundWithGLoRIHead(backbone=base_model, glori_module=glori_clean, args=args)\n",
    "\n",
    "#train_model = train_model.to('cpu')\n",
    "# 5) Move model to device\n",
    "train_model = train_model.to(DEVICE)\n",
    "\n",
    "# Load checkpoint\n",
    "model_ckpt = torch.load(\"/kaggle/input/all-data-chexfound-recs-div-a/CheXFound/model3.pth\", map_location=DEVICE,weights_only=False )\n",
    "train_model.load_state_dict(model_ckpt[\"model_state_dict\"])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 3) Freeze backbone, ensure glori params are trainable\n",
    "for p in train_model.backbone.parameters():\n",
    "    p.requires_grad = False\n",
    "for p in train_model.glori.parameters():\n",
    "    p.requires_grad = True\n",
    "\n",
    "\n",
    "# 4) If you have multiple GPUs, wrap with nn.DataParallel (NOT DDP)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Wrapping train_model with nn.DataParallel for multi-GPU\")\n",
    "    train_model = nn.DataParallel(train_model)\n",
    "\n",
    "\n",
    "\n",
    "# IMPORTANT: make sure the name used in the rest of your loop refers to the wrapped model\n",
    "model = train_model   \n",
    "\n",
    "#EMA\n",
    "ema = ModelEMA(model, decay=0.99967)\n",
    "\n",
    "# ema_ckpt = torch.load(\"/kaggle/input/all-data-chexfound-recs-div-a/CheXFound/ema_model_f3.pth\",\n",
    "#                       #map_location='cpu',\n",
    "#                       weights_only=False )\n",
    "ema.ema.load_state_dict(model_ckpt[\"ema_state_dict\"])\n",
    "\n",
    "\n",
    "# 6) Build optimizer from glori params safely (now use `model`)\n",
    "def get_glori_params_from_model(m):\n",
    "    core = getattr(m, \"module\", m)\n",
    "    gl = getattr(core, \"glori\", None)\n",
    "    if gl is None:\n",
    "        raise RuntimeError(\"model has no .glori attribute; inspect model.\")\n",
    "    gl_core = getattr(gl, \"module\", gl)\n",
    "    return [p for p in gl_core.parameters() if p.requires_grad]\n",
    "\n",
    "glori_trainable = get_glori_params_from_model(model)\n",
    "print(\"Trainable glori params count:\", sum(p.numel() for p in glori_trainable))\n",
    "\n",
    "\n",
    "optimizer = torch.optim.AdamW(glori_trainable, lr=2e-4, weight_decay=1e-5)\n",
    "#load optimizer\n",
    "optimizer.load_state_dict(model_ckpt[\"optimizer_state_dict\"])\n",
    "\n",
    "    \n",
    "# Dataset\n",
    "train_dataset = ChestXrayDataset(\n",
    "    df=train_df,\n",
    "    img_dir=\"/kaggle/input/600-p-div-a-data/train1_resized\",\n",
    "    transform=train_tfms\n",
    ")\n",
    "\n",
    "# # (for a real setup, you'd split train/val from train1.csv)\n",
    "# val_dataset = ChestXrayDataset(\n",
    "#     df=val_df,\n",
    "#     img_dir=\"/kaggle/input/xray-data-div-b-600p-95/train2_resized\",\n",
    "#     transform=val_tfms\n",
    "# )\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    num_workers=16,   \n",
    "    #num_workers=4,   \n",
    "    pin_memory=True\n",
    ")\n",
    "# val_loader = DataLoader(\n",
    "#     val_dataset,\n",
    "#     batch_size=64,\n",
    "#     shuffle=False,\n",
    "#     num_workers=16,\n",
    "#     #num_workers=4,\n",
    "#     pin_memory=True\n",
    "# )\n",
    "\n",
    "for epoch in range(3,EPOCHS):\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "    \n",
    "    train_loss = train_one_epoch(model, train_loader, optimizer, criterion, ema)\n",
    "\n",
    "    #if epoch >1:\n",
    "            \n",
    "    #val_loss, val_auc, per_label_auc = validate(ema.ema, val_loader, criterion)\n",
    "    print(f\"[Epoch {epoch+1}] TrainLoss={train_loss:.4f} \")\n",
    "\n",
    "    # print(f\"[Epoch {epoch+1}] TrainLoss={train_loss:.4f} | EMA ValLoss={val_loss:.4f} | AUC={val_auc:.4f}\")\n",
    "    # print(\"Per-label AUROC:\", {k: f\"{v:.3f}\" for k, v in per_label_auc.items()})\n",
    "\n",
    "    \n",
    "    save_path = f\"best_model_f{epoch+1}.pth\"\n",
    "    torch.save({\n",
    "        \"epoch\": epoch+1,\n",
    "        \"model_state_dict\": get_model(model).state_dict(),  \n",
    "        \"optimizer_state_dict\": optimizer.state_dict()\n",
    "    }, save_path)\n",
    "\n",
    "    # also save EMA\n",
    "    if ema is not None:\n",
    "        torch.save({\n",
    "            \"epoch\": epoch+1,\n",
    "            \"ema_state_dict\": ema.state_dict()\n",
    "        }, f\"ema_model_f{epoch+1}.pth\")\n",
    "\n",
    "    print(f\"✅ Saved new best model  -> {save_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1bafde9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-01T18:47:41.058266Z",
     "iopub.status.busy": "2025-10-01T18:47:41.057839Z",
     "iopub.status.idle": "2025-10-01T18:47:41.063405Z",
     "shell.execute_reply": "2025-10-01T18:47:41.062625Z"
    },
    "papermill": {
     "duration": 0.419954,
     "end_time": "2025-10-01T18:47:41.064771",
     "exception": false,
     "start_time": "2025-10-01T18:47:40.644817",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save_path = f\"best_model_f{epoch+1}.pth\"\n",
    "# torch.save({\n",
    "#     \"epoch\": epoch+1,\n",
    "#     \"model_state_dict\": get_model(model).state_dict(),  \n",
    "#     \"optimizer_state_dict\": optimizer.state_dict()\n",
    "# }, save_path)\n",
    "\n",
    "# # also save EMA\n",
    "# if ema is not None:\n",
    "#     torch.save({\n",
    "#         \"epoch\": epoch+1,\n",
    "#         \"ema_state_dict\": ema.state_dict()\n",
    "#     }, f\"ema_model_f{epoch+1}.pth\")\n",
    "\n",
    "# print(f\"✅ Saved model  \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54733112",
   "metadata": {
    "papermill": {
     "duration": 0.310814,
     "end_time": "2025-10-01T18:47:41.662659",
     "exception": false,
     "start_time": "2025-10-01T18:47:41.351845",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 13449579,
     "sourceId": 112899,
     "sourceType": "competition"
    },
    {
     "datasetId": 8304094,
     "sourceId": 13109235,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 264923570,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 31366.90275,
   "end_time": "2025-10-01T18:47:47.442959",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-10-01T10:05:00.540209",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
